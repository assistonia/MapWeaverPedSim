#!/usr/bin/env python3
"""
ë¹ ë¥¸ DiPPeR í•™ìŠµ ì½”ë“œ - ë³‘ë ¬ ë°ì´í„° ìˆ˜ì§‘
"""
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import multiprocessing as mp
from concurrent.futures import ProcessPoolExecutor, as_completed
import argparse
import os
import json
from tqdm import tqdm
import time

# CUDA ë©€í‹°í”„ë¡œì„¸ì‹± ë¬¸ì œ í•´ê²°
if __name__ == "__main__":
    mp.set_start_method('spawn', force=True)

from robot_simuator_dippeR import DiPPeR, RobotSimulatorDiPPeR

def collect_single_episode(args):
    """ë‹¨ì¼ ì—í”¼ì†Œë“œ ë°ì´í„° ìˆ˜ì§‘ (ë©€í‹°í”„ë¡œì„¸ì‹±ìš©)"""
    xml_file, episode_id, episodes_per_process = args
    
    try:
        # ê° í”„ë¡œì„¸ìŠ¤ë§ˆë‹¤ ë³„ë„ ì‹œë®¬ë ˆì´í„° ìƒì„± (CPUë§Œ ì‚¬ìš©)
        os.environ['CUDA_VISIBLE_DEVICES'] = ''  # ìì‹ í”„ë¡œì„¸ìŠ¤ì—ì„œ GPU ì‚¬ìš© ê¸ˆì§€
        simulator = RobotSimulatorDiPPeR(xml_file, model_path=None)
        simulator.use_dipperp = False  # A* í´ë°±ë§Œ ì‚¬ìš©
        
        episode_data = []
        
        for i in range(episodes_per_process):
            # ì•ˆì „í•œ ì‹œì‘/ëª©í‘œì  ìƒì„±
            start_pos, goal_pos = generate_safe_positions(simulator)
            if start_pos is None:
                continue
                
            # A* ê²½ë¡œ ê³„íš
            path = simulator.fallback_astar_planning(start_pos, goal_pos)
            if path is None or len(path) < 10:
                continue
            
            # 50ê°œ ì›¨ì´í¬ì¸íŠ¸ë¡œ ë³´ê°„
            waypoints = interpolate_path(path, 50)
            if waypoints is None:
                continue
            
            # ì•ˆì „ì„± ê²€ì¦
            if not all(simulator.is_position_safe(wp) for wp in waypoints):
                continue
            
            # ë°ì´í„° ì €ì¥
            data_item = {
                'cost_map': simulator.fused_cost_map.copy(),
                'start_pos': np.array([start_pos[0]/6.0, start_pos[1]/6.0]),
                'goal_pos': np.array([goal_pos[0]/6.0, goal_pos[1]/6.0]),
                'path': np.array([[wp[0]/6.0, wp[1]/6.0] for wp in waypoints])
            }
            episode_data.append(data_item)
            
        print(f"í”„ë¡œì„¸ìŠ¤ {episode_id}: {len(episode_data)}ê°œ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
        return episode_data
        
    except Exception as e:
        print(f"í”„ë¡œì„¸ìŠ¤ {episode_id} ì˜¤ë¥˜: {e}")
        return []

def generate_safe_positions(simulator):
    """ì•ˆì „í•œ ì‹œì‘/ëª©í‘œì  ìƒì„±"""
    safe_zones = [
        (-4.5, -0.5, -4.5, 1.5),  # ì™¼ìª½ ìœ„
        (-4.5, -0.5, -2.0, -1.5), # ì™¼ìª½ ì•„ë˜
        (2.5, 3.5, -4.5, -0.5),   # ì˜¤ë¥¸ìª½ ì•„ë˜
        (2.5, 3.5, 1.0, 2.0),     # ì˜¤ë¥¸ìª½ ìœ„
        (-0.5, 1.5, 3.0, 4.5)     # ìœ„ìª½ ì¤‘ì•™
    ]
    
    for _ in range(20):  # ì‹œë„ íšŸìˆ˜ ì¤„ì„
        # ì•ˆì „ êµ¬ì—­ì—ì„œ ì„ íƒ
        zone1 = safe_zones[np.random.randint(len(safe_zones))]
        zone2 = safe_zones[np.random.randint(len(safe_zones))]
        
        start_pos = [np.random.uniform(zone1[0], zone1[1]), 
                    np.random.uniform(zone1[2], zone1[3])]
        goal_pos = [np.random.uniform(zone2[0], zone2[1]), 
                   np.random.uniform(zone2[2], zone2[3])]
        
        # ê±°ë¦¬ ì²´í¬
        if np.linalg.norm(np.array(goal_pos) - np.array(start_pos)) < 2.0:
            continue
            
        # ì•ˆì „ì„± ì²´í¬
        if (simulator.is_position_safe(start_pos) and 
            simulator.is_position_safe(goal_pos)):
            return start_pos, goal_pos
    
    return None, None

def interpolate_path(path, target_points):
    """ê²½ë¡œ ë³´ê°„"""
    if len(path) < 2:
        return None
    
    path_array = np.array(path)
    distances = np.cumsum([0] + [np.linalg.norm(path_array[i+1] - path_array[i]) 
                                for i in range(len(path_array)-1)])
    total_distance = distances[-1]
    
    if total_distance < 1e-6:
        return None
    
    target_distances = np.linspace(0, total_distance, target_points)
    interpolated_x = np.interp(target_distances, distances, path_array[:, 0])
    interpolated_y = np.interp(target_distances, distances, path_array[:, 1])
    
    return np.column_stack([interpolated_x, interpolated_y])

def collect_parallel_data(xml_file, total_episodes=2000, num_processes=8):
    """ë³‘ë ¬ë¡œ ë°ì´í„° ìˆ˜ì§‘"""
    episodes_per_process = total_episodes // num_processes
    
    print(f"ğŸš€ {num_processes}ê°œ í”„ë¡œì„¸ìŠ¤ë¡œ ì´ {total_episodes}ê°œ ì—í”¼ì†Œë“œ ìˆ˜ì§‘ ì‹œì‘")
    print(f"ê° í”„ë¡œì„¸ìŠ¤ë‹¹ {episodes_per_process}ê°œ ì—í”¼ì†Œë“œ")
    
    # í”„ë¡œì„¸ìŠ¤ ì¸ì ì¤€ë¹„
    process_args = [(xml_file, i, episodes_per_process) 
                   for i in range(num_processes)]
    
    all_data = []
    
    # ë³‘ë ¬ ì‹¤í–‰ (spawn ë°©ì‹)
    with ProcessPoolExecutor(max_workers=num_processes) as executor:
        # ì‘ì—… ì œì¶œ
        futures = [executor.submit(collect_single_episode, args) 
                  for args in process_args]
        
        # ì§„í–‰ë¥  í‘œì‹œ
        for future in tqdm(as_completed(futures), total=num_processes, 
                          desc="ë³‘ë ¬ ë°ì´í„° ìˆ˜ì§‘"):
            episode_data = future.result()
            all_data.extend(episode_data)
    
    print(f"âœ… ì´ {len(all_data)}ê°œ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")
    return all_data

class FastDataset(Dataset):
    def __init__(self, data_list):
        self.data = data_list
    
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        item = self.data[idx]
        cost_map = torch.from_numpy(item['cost_map']).float().unsqueeze(0)
        start_pos = torch.from_numpy(item['start_pos']).float()
        goal_pos = torch.from_numpy(item['goal_pos']).float()
        path = torch.from_numpy(item['path']).float()
        return cost_map, start_pos, goal_pos, path

def train_fast_dipperp(data_list, device='cuda', epochs=100):
    """ë¹ ë¥¸ DiPPeR í•™ìŠµ"""
    dataset = FastDataset(data_list)
    dataloader = DataLoader(dataset, batch_size=64, shuffle=True, 
                           num_workers=4, pin_memory=True)
    
    model = DiPPeR(visual_feature_dim=512, path_dim=2, max_timesteps=1000).to(device)
    optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-6)
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)
    
    best_loss = float('inf')
    
    print(f"ğŸ¯ {device}ì—ì„œ í•™ìŠµ ì‹œì‘: {len(dataset)}ê°œ ë°ì´í„°, {epochs} ì—í¬í¬")
    
    for epoch in range(epochs):
        model.train()
        total_loss = 0
        
        pbar = tqdm(dataloader, desc=f"Epoch {epoch+1}/{epochs}")
        for batch in pbar:
            cost_maps, start_pos, goal_pos, paths = batch
            batch_size = cost_maps.shape[0]
            
            # GPUë¡œ ì´ë™
            cost_maps = cost_maps.to(device, non_blocking=True)
            start_pos = start_pos.to(device, non_blocking=True)
            goal_pos = goal_pos.to(device, non_blocking=True)
            paths = paths.to(device, non_blocking=True)
            
            # Diffusion í•™ìŠµ
            timesteps = torch.randint(0, model.max_timesteps, (batch_size,), device=device)
            noise = torch.randn_like(paths)
            alpha_cumprod = model.alphas_cumprod[timesteps].view(-1, 1, 1)
            noisy_paths = torch.sqrt(alpha_cumprod) * paths + torch.sqrt(1 - alpha_cumprod) * noise
            
            start_goal_pos = torch.cat([start_pos, goal_pos], dim=-1)
            predicted_noise = model(cost_maps, noisy_paths, timesteps, start_goal_pos)
            
            loss = nn.MSELoss()(predicted_noise, noise)
            
            optimizer.zero_grad()
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
            optimizer.step()
            
            total_loss += loss.item()
            pbar.set_postfix({'Loss': f'{loss.item():.6f}'})
        
        avg_loss = total_loss / len(dataloader)
        scheduler.step()
        
        print(f"Epoch {epoch+1}: Loss = {avg_loss:.6f}")
        
        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥
        if avg_loss < best_loss:
            best_loss = avg_loss
            torch.save({
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'epoch': epoch,
                'loss': avg_loss
            }, 'models/dipperp_fast_best.pth')
            print(f"ğŸ¯ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥: {avg_loss:.6f}")
    
    return model

def main():
    parser = argparse.ArgumentParser(description='ë¹ ë¥¸ DiPPeR í•™ìŠµ')
    parser.add_argument('--xml_file', default='scenarios/Circulation1.xml')
    parser.add_argument('--episodes', type=int, default=2000)
    parser.add_argument('--processes', type=int, default=8)
    parser.add_argument('--epochs', type=int, default=100)
    parser.add_argument('--device', default='cuda')
    
    args = parser.parse_args()
    
    # GPU í™•ì¸
    if args.device == 'cuda' and torch.cuda.is_available():
        device = torch.device('cuda')
        print(f"ğŸš€ GPU ì‚¬ìš©: {torch.cuda.get_device_name(0)}")
    else:
        device = torch.device('cpu')
        print("ğŸ’» CPU ì‚¬ìš©")
    
    # ë³‘ë ¬ ë°ì´í„° ìˆ˜ì§‘
    start_time = time.time()
    data_list = collect_parallel_data(args.xml_file, args.episodes, args.processes)
    collect_time = time.time() - start_time
    
    print(f"â±ï¸ ë°ì´í„° ìˆ˜ì§‘ ì‹œê°„: {collect_time:.1f}ì´ˆ")
    if len(data_list) > 0:
        print(f"ğŸ“Š ì´ˆë‹¹ {len(data_list)/collect_time:.1f}ê°œ ë°ì´í„° ìˆ˜ì§‘")
    
    if len(data_list) == 0:
        print("âŒ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!")
        return
    
    # ë¹ ë¥¸ í•™ìŠµ
    os.makedirs('models', exist_ok=True)
    model = train_fast_dipperp(data_list, device, args.epochs)
    
    print("âœ… í•™ìŠµ ì™„ë£Œ!")

if __name__ == "__main__":
    main() 