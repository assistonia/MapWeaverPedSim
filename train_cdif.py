#!/usr/bin/env python3
"""
CDIF: CCTV-informed Diffusion Training Pipeline

í•µì‹¬ í˜ì‹ :
- í¸ì¬í•˜ëŠ” CCTV ì¸í”„ë¼ì˜ ì „ëµì  í™œìš©ì„ í†µí•œ ì œë¡œ-ë¹„ìš© ì„¼ì„œ í™•ì¥
- ì •ì  ì¥ì• ë¬¼ê³¼ ë™ì  ì‚¬íšŒì  ìš”ì†Œë¥¼ ë‹¨ì¼ í‘œí˜„ ê³µê°„ìœ¼ë¡œ í†µí•©í•˜ëŠ” í™˜ê²½ ëª¨ë¸ë§
- í™•ë¥ ì  ë‹¤ì¤‘ ê²½ë¡œ í›„ë³´ ë™ì‹œ ìƒì„±ì„ ìœ„í•œ ë‹¤ì¤‘ ëª¨ë‹¬ í•™ìŠµ
- ì‹¤ì‹œê°„ ì ì‘í˜• ë‚´ë¹„ê²Œì´ì…˜ì„ ìœ„í•œ ê³„ì¸µì  ìœµí•© êµ¬ì¡°

ì°¨ë³„í™” í¬ì¸íŠ¸:
- vs CGIP: ê²°ì •ì  ë‹¨ì¼ í•´ â†’ í™•ë¥ ì  ë‹¤ì¤‘ ê²½ë¡œ ìƒì„±
- vs DiPPeR-Legged: ë‹¨ìˆœ ì¥ì• ë¬¼ íšŒí”¼ â†’ ì‚¬íšŒì  ë§¥ë½ ì¸ì‹
- ê¸°ì¡´ ì¸í”„ë¼ í™œìš© + ì²¨ë‹¨ ìƒì„± ëª¨ë¸ë§ ê¸°ë²• ìœµí•©
"""

import os
import sys
import time
import json
import random
import argparse
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass

import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torch.utils.tensorboard import SummaryWriter
import matplotlib
matplotlib.use('Agg')  # ì„œë²„ìš© ë°±ì—”ë“œ
import matplotlib.pyplot as plt
from tqdm import tqdm

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ
from cdif_model import CDIFModel, DDPMScheduler
from robot_simulator_cgip import RobotSimulator

@dataclass
class CDIFConfig:
    """CDIF í•™ìŠµ ì„¤ì • - ì‚¬íšŒì  ë§¥ë½ ì¸ì‹ ë‹¤ì¤‘ ê²½ë¡œ ìƒì„±"""
    # ëª¨ë¸ ì„¤ì •
    max_waypoints: int = 8
    feature_dim: int = 256
    hidden_dim: int = 512
    num_layers: int = 6
    num_path_modes: int = 3  # ê²½ë¡œ ëª¨ë“œ: 0=ì§ì ‘, 1=ì‚¬íšŒì , 2=ìš°íšŒ
    
    # í•™ìŠµ ì„¤ì •
    batch_size: int = 32
    learning_rate: float = 1e-4
    weight_decay: float = 1e-5
    num_epochs: int = 100
    warmup_epochs: int = 5
    
    # Diffusion ì„¤ì •
    num_train_timesteps: int = 1000
    beta_schedule: str = "cosine"
    
    # ë°ì´í„° ì„¤ì •
    target_samples: int = 10000
    train_ratio: float = 0.9
    
    # GPU ì„¤ì •
    mixed_precision: bool = True
    gradient_clip: float = 1.0
    
    # ì²´í¬í¬ì¸íŠ¸ ì„¤ì •
    save_every: int = 5
    validate_every: int = 2
    early_stopping_patience: int = 15

class SocialContextWaypointExtractor:
    """ì‚¬íšŒì  ë§¥ë½ ì¸ì‹ ì›¨ì´í¬ì¸íŠ¸ ì¶”ì¶œê¸° - ë‹¤ì¤‘ ëª¨ë‹¬ ê²½ë¡œ ìƒì„±"""
    
    def __init__(self, grid_size=0.2):
        self.grid_size = grid_size
        # ê²½ë¡œ ìŠ¤íƒ€ì¼ ì •ì˜
        self.path_styles = {
            0: "direct",     # ì§ì ‘ ê²½ë¡œ (ìµœë‹¨ê±°ë¦¬)
            1: "social",     # ì‚¬íšŒì  ê²½ë¡œ (ì‚¬ëŒ íšŒí”¼)
            2: "detour"      # ìš°íšŒ ê²½ë¡œ (ì•ˆì „ ìš°ì„ )
        }
        
    def extract_multimodal_waypoints(self, start_pos, goal_pos, simulator, max_waypoints=6):
        """ë‹¤ì¤‘ ëª¨ë‹¬ ì›¨ì´í¬ì¸íŠ¸ ì¶”ì¶œ - ì‚¬íšŒì  ë§¥ë½ë³„ ë‹¤ì–‘í•œ ê²½ë¡œ ìŠ¤íƒ€ì¼"""
        
        # ê¸°ë³¸ A* ê²½ë¡œ (ì§ì ‘ ê²½ë¡œ)
        direct_path = simulator.a_star(start_pos, goal_pos)
        if not direct_path or len(direct_path) < 2:
            return {0: [start_pos, goal_pos], 1: [start_pos, goal_pos], 2: [start_pos, goal_pos]}
        
        # ë‹¤ì¤‘ ëª¨ë‹¬ ê²½ë¡œ ìƒì„±
        multimodal_paths = {}
        
        # ëª¨ë“œ 0: ì§ì ‘ ê²½ë¡œ (ìµœë‹¨ê±°ë¦¬)
        multimodal_paths[0] = self._sample_waypoints(direct_path, max_waypoints)
        
        # ëª¨ë“œ 1: ì‚¬íšŒì  ê²½ë¡œ (ì‚¬ëŒ ë°€ë„ íšŒí”¼)
        social_path = self._generate_social_aware_path(start_pos, goal_pos, simulator)
        multimodal_paths[1] = self._sample_waypoints(social_path, max_waypoints)
        
        # ëª¨ë“œ 2: ìš°íšŒ ê²½ë¡œ (ì•ˆì „ ìš°ì„ )
        detour_path = self._generate_detour_path(start_pos, goal_pos, simulator)
        multimodal_paths[2] = self._sample_waypoints(detour_path, max_waypoints)
        
        return multimodal_paths
    
    def _sample_waypoints(self, path, max_waypoints):
        """ê²½ë¡œì—ì„œ ì›¨ì´í¬ì¸íŠ¸ ê· ë“± ìƒ˜í”Œë§"""
        if len(path) <= max_waypoints:
            return path
        
        indices = np.linspace(0, len(path) - 1, max_waypoints, dtype=int)
        sampled_waypoints = [path[i] for i in indices]
        return sampled_waypoints
    
    def _generate_social_aware_path(self, start_pos, goal_pos, simulator):
        """ì‚¬íšŒì  ì¸ì‹ ê²½ë¡œ ìƒì„± (Individual Space ì˜ì—­ íšŒí”¼)"""
        # ì‚¬íšŒì  ë¹„ìš©ë§µ ê¸°ë°˜ A* ê²½ë¡œ ê³„íš
        return self._social_cost_astar(start_pos, goal_pos, simulator)
    
    def _generate_detour_path(self, start_pos, goal_pos, simulator):
        """ìš°íšŒ ê²½ë¡œ ìƒì„± (ì¥ì• ë¬¼ ë§ˆì§„ ì¦ê°€)"""
        # ì¥ì• ë¬¼ ì£¼ë³€ ë§ˆì§„ì„ ì¦ê°€ì‹œí‚¨ A* ê²½ë¡œ ê³„íš
        return self._safe_margin_astar(start_pos, goal_pos, simulator)
    
    def _social_cost_astar(self, start_pos, goal_pos, simulator):
        """ì‚¬íšŒì  ë¹„ìš©ì„ ê³ ë ¤í•œ A* ê²½ë¡œ ê³„íš"""
        start = (int((start_pos[0] + 6) / simulator.grid_size), int((start_pos[1] + 6) / simulator.grid_size))
        goal = (int((goal_pos[0] + 6) / simulator.grid_size), int((goal_pos[1] + 6) / simulator.grid_size))
        
        # 60x60 ê·¸ë¦¬ë“œ ê¸°ë°˜ ë™ì  ì¥ì• ë¬¼ ë§µ ìƒì„±
        dynamic_grid = simulator.grid.copy()
        
        # ì—ì´ì „íŠ¸ë¥¼ ë™ì  ì¥ì• ë¬¼ë¡œ ì¶”ê°€ (60x60 ê·¸ë¦¬ë“œ)
        for agent in simulator.agents:
            x_idx = int((agent.pos[0] + 6) / simulator.grid_size)
            y_idx = int((agent.pos[1] + 6) / simulator.grid_size)
            radius_idx = int(agent.radius / simulator.grid_size)
            
            for i in range(-radius_idx, radius_idx + 1):
                for j in range(-radius_idx, radius_idx + 1):
                    if 0 <= x_idx + i < 60 and 0 <= y_idx + j < 60:
                        if i*i + j*j <= radius_idx*radius_idx:
                            dynamic_grid[y_idx + j, x_idx + i] = 1
        
        # ì‚¬íšŒì  ë¹„ìš©ì´ ë†’ì€ ì˜ì—­ì„ ì¥ì• ë¬¼ë¡œ ì²˜ë¦¬
        social_map = np.zeros((60, 60))
        for agent in simulator.agents:
            if not agent.finished and simulator.is_in_cctv_coverage(agent.pos):
                for i in range(60):
                    for j in range(60):
                        x = (j * simulator.grid_size) - 6
                        y = (i * simulator.grid_size) - 6
                        is_value = agent.calculate_individual_space([x, y])
                        social_map[i, j] = max(social_map[i, j], is_value)
        
        # ì‚¬íšŒì  ë¹„ìš©ì´ ë†’ì€ ì˜ì—­ì„ ì¥ì• ë¬¼ë¡œ ì²˜ë¦¬ (ì„ê³„ê°’: 0.3)
        social_obstacle_mask = social_map > 0.3
        dynamic_grid = np.logical_or(dynamic_grid, social_obstacle_mask).astype(int)
        
        return self._astar_with_cost_map(start, goal, dynamic_grid, simulator)
    
    def _safe_margin_astar(self, start_pos, goal_pos, simulator):
        """ì•ˆì „ ë§ˆì§„ì„ ì¦ê°€ì‹œí‚¨ A* ê²½ë¡œ ê³„íš"""
        start = (int((start_pos[0] + 6) / simulator.grid_size), int((start_pos[1] + 6) / simulator.grid_size))
        goal = (int((goal_pos[0] + 6) / simulator.grid_size), int((goal_pos[1] + 6) / simulator.grid_size))
        
        # ì¥ì• ë¬¼ ë§ˆì§„ í™•ì¥
        expanded_grid = self._expand_obstacles(simulator.grid, margin=3)
        
        # 60x60 ê·¸ë¦¬ë“œ ê¸°ë°˜ ë™ì  ì¥ì• ë¬¼ ì¶”ê°€
        for agent in simulator.agents:
            x_idx = int((agent.pos[0] + 6) / simulator.grid_size)
            y_idx = int((agent.pos[1] + 6) / simulator.grid_size)
            radius_idx = int(agent.radius / simulator.grid_size)
            
            for i in range(-radius_idx, radius_idx + 1):
                for j in range(-radius_idx, radius_idx + 1):
                    if 0 <= x_idx + i < 60 and 0 <= y_idx + j < 60:
                        if i*i + j*j <= radius_idx*radius_idx:
                            expanded_grid[y_idx + j, x_idx + i] = 1
        
        return self._astar_with_cost_map(start, goal, expanded_grid, simulator)
    
    def _expand_obstacles(self, grid, margin=2):
        """ì¥ì• ë¬¼ ì£¼ë³€ì— ë§ˆì§„ ì¶”ê°€ (ìˆ˜ë™ êµ¬í˜„)"""
        expanded = grid.copy()
        h, w = grid.shape
        
        for i in range(h):
            for j in range(w):
                if grid[i, j] == 1:  # ì¥ì• ë¬¼ì¸ ê²½ìš°
                    # ì£¼ë³€ ë§ˆì§„ ì˜ì—­ì— ì¥ì• ë¬¼ í‘œì‹œ
                    for di in range(-margin, margin + 1):
                        for dj in range(-margin, margin + 1):
                            ni, nj = i + di, j + dj
                            if 0 <= ni < h and 0 <= nj < w:
                                expanded[ni, nj] = 1
        return expanded
    
    def _astar_with_cost_map(self, start, goal, cost_grid, simulator):
        """ë¹„ìš©ë§µì„ ì‚¬ìš©í•œ A* ê²½ë¡œ ê³„íš"""
        from heapq import heappush, heappop
        
        frontier = []
        heappush(frontier, (0, start))
        came_from = {start: None}
        cost_so_far = {start: 0}
        
        while frontier:
            current = heappop(frontier)[1]
            
            if current == goal:
                break
                
            for next_pos in self._get_neighbors_with_cost(current, cost_grid):
                new_cost = cost_so_far[current] + self._movement_cost(current, next_pos)
                if next_pos not in cost_so_far or new_cost < cost_so_far[next_pos]:
                    cost_so_far[next_pos] = new_cost
                    priority = new_cost + simulator.heuristic(goal, next_pos)
                    heappush(frontier, (priority, next_pos))
                    came_from[next_pos] = current
        
        # ê²½ë¡œ ì¬êµ¬ì„±
        path = []
        current = goal
        while current is not None:
            x = current[0] * simulator.grid_size - 6
            y = current[1] * simulator.grid_size - 6
            path.append([x, y])
            current = came_from.get(current)
        path.reverse()
        return path if path else [start_pos, goal_pos]
    
    def _get_neighbors_with_cost(self, pos, cost_grid):
        """ë¹„ìš©ë§µ ê¸°ë°˜ ì´ì›ƒ ë…¸ë“œ íƒìƒ‰"""
        x, y = pos
        neighbors = []
        for dx, dy in [(0,1), (1,0), (0,-1), (-1,0), (1,1), (-1,1), (1,-1), (-1,-1)]:
            new_x = x + dx
            new_y = y + dy
            if (0 <= new_x < cost_grid.shape[1] and 0 <= new_y < cost_grid.shape[0] and 
                cost_grid[new_y, new_x] == 0):
                neighbors.append((new_x, new_y))
        return neighbors
    
    def _movement_cost(self, current, next_pos):
        """ì´ë™ ë¹„ìš© ê³„ì‚° (ëŒ€ê°ì„  ì´ë™ ê³ ë ¤)"""
        dx = abs(next_pos[0] - current[0])
        dy = abs(next_pos[1] - current[1])
        return 1.414 if (dx + dy) == 2 else 1.0

class CDIFDataset(Dataset):
    """CDIF í•™ìŠµ ë°ì´í„°ì…‹"""
    
    def __init__(self, data_samples: List[Dict], config: CDIFConfig):
        self.samples = data_samples
        self.config = config
        
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        sample = self.samples[idx]
        
        # ë°ì´í„° ë¡œë“œ (JSONì—ì„œ ë¡œë“œëœ ë¦¬ìŠ¤íŠ¸ë¥¼ NumPyë¡œ ë³€í™˜)
        integrated_cost_map = torch.from_numpy(np.array(sample['integrated_cost_map'])).float()  # [3, 60, 60]
        start_pos = torch.from_numpy(np.array(sample['start_pos'])).float()  # [2]
        goal_pos = torch.from_numpy(np.array(sample['goal_pos'])).float()  # [2]
        waypoints = np.array(sample['strategic_waypoints'])  # Convert to numpy array
        path_mode = sample.get('path_mode', 0)  # ê²½ë¡œ ëª¨ë“œ (ê¸°ë³¸ê°’: 0)
        
        # ì›¨ì´í¬ì¸íŠ¸ë¥¼ ê³ ì • ê¸¸ì´ë¡œ íŒ¨ë”©
        max_waypoints = self.config.max_waypoints
        num_waypoints = len(waypoints)
        
        if num_waypoints > max_waypoints:
            # ë„ˆë¬´ ë§ìœ¼ë©´ ì˜ë¼ë‚´ê¸°
            waypoints = waypoints[:max_waypoints]
            num_waypoints = max_waypoints
        else:
            # ë¶€ì¡±í•˜ë©´ ë§ˆì§€ë§‰ ì ìœ¼ë¡œ íŒ¨ë”©
            waypoints_padded = waypoints.tolist()
            while len(waypoints_padded) < max_waypoints:
                waypoints_padded.append(waypoints_padded[-1])
            waypoints = np.array(waypoints_padded)
        
        waypoints_tensor = torch.from_numpy(waypoints).float()  # [max_waypoints, 2]
        num_waypoints_tensor = torch.tensor(num_waypoints, dtype=torch.long)
        path_mode_tensor = torch.tensor(path_mode, dtype=torch.long)
        
        return {
            'integrated_cost_map': integrated_cost_map,  # 3ì±„ë„ í†µí•© ë¹„ìš©ë§µ
            'start_pos': start_pos,
            'goal_pos': goal_pos,
            'waypoints': waypoints_tensor,
            'num_waypoints': num_waypoints_tensor,
            'path_mode': path_mode_tensor
        }

class CDIFDataCollector:
    """CDIF ë°ì´í„° ìˆ˜ì§‘ê¸°"""
    
    def __init__(self, config: CDIFConfig, output_dir='training_data_cdif'):
        self.config = config
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        # ì‹œë®¬ë ˆì´í„° ì´ˆê¸°í™” (ì‚¬íšŒì  ë§¥ë½ì„ ìœ„í•´ Congestion1.xml ì‚¬ìš©)
        self.simulator = RobotSimulator('scenarios/Congestion1.xml')
        self.extractor = SocialContextWaypointExtractor()
        
    def collect_data(self) -> List[Dict]:
        """ì „ëµì  ì›¨ì´í¬ì¸íŠ¸ ë°ì´í„° ìˆ˜ì§‘"""
        print(f"ğŸ¯ ëª©í‘œ: {self.config.target_samples:,}ê°œ CDIF ë°ì´í„° ìˆ˜ì§‘")
        
        collected_data = []
        
        # ì•ˆì „í•œ ìœ„ì¹˜ ìƒì„±ì„ ìœ„í•œ ì˜ì—­ ì •ì˜
        safe_zones = [
            (-5.5, -5.5, -0.5, -0.5),  # ì¢Œí•˜
            (-5.5, 0.5, -0.5, 5.5),    # ì¢Œìƒ
            (0.5, -5.5, 5.5, -0.5),    # ìš°í•˜
            (0.5, 0.5, 5.5, 5.5),      # ìš°ìƒ
            (-2.0, -2.0, 2.0, 2.0)     # ì¤‘ì•™
        ]
        
        pbar = tqdm(total=self.config.target_samples, desc="CDIF ë°ì´í„° ìˆ˜ì§‘")
        
        while len(collected_data) < self.config.target_samples:
            # ëœë¤ ì‹œì‘/ëª©í‘œì  ìƒì„±
            start_pos = self._generate_safe_position(safe_zones)
            goal_pos = self._generate_safe_position(safe_zones)
            
            if start_pos is None or goal_pos is None:
                continue
            
            # ê±°ë¦¬ ì²´í¬ (ìµœì†Œ 3m ì´ìƒ)
            dist = np.linalg.norm(np.array(start_pos) - np.array(goal_pos))
            if dist < 3.0:
                continue
            
            # ğŸš¨ ì‚¬íšŒì  ë§¥ë½ ìƒì„±ì„ ìœ„í•´ ì‹œë®¬ë ˆì´ì…˜ ì—…ë°ì´íŠ¸
            # ì—ì´ì „íŠ¸ë“¤ì„ ì—…ë°ì´íŠ¸í•˜ì—¬ ì‚¬íšŒì  ë¹„ìš©ë§µ ìƒì„±
            for agent in self.simulator.agents:
                agent.update(self.simulator.agents, self.simulator.obstacles)
            self.simulator.update()  # Individual Space ë§µ ì—…ë°ì´íŠ¸
            
            # ë‹¤ì¤‘ ëª¨ë‹¬ ì›¨ì´í¬ì¸íŠ¸ ì¶”ì¶œ (ì‚¬íšŒì  ë§¥ë½ ê³ ë ¤)
            multimodal_waypoints = self.extractor.extract_multimodal_waypoints(
                start_pos, goal_pos, self.simulator, 
                max_waypoints=self.config.max_waypoints
            )
            
            # ëœë¤í•˜ê²Œ í•˜ë‚˜ì˜ ëª¨ë“œ ì„ íƒ (í•™ìŠµ ë°ì´í„° ë‹¤ì–‘ì„±)
            selected_mode = random.randint(0, 2)
            strategic_waypoints = multimodal_waypoints[selected_mode]
            
            if len(strategic_waypoints) >= 2:
                # í†µí•© ë¹„ìš©ë§µ ìƒì„± (3ì±„ë„: ì •ì  + ì‚¬íšŒì  + íë¦„)
                integrated_cost_map = self._create_integrated_cost_map()
                
                # ë°ì´í„° ì •ê·œí™” (-6~6 â†’ -1~1)
                data_sample = {
                    'integrated_cost_map': integrated_cost_map,  # [3, 60, 60]
                    'start_pos': np.array([start_pos[0]/6.0, start_pos[1]/6.0]),
                    'goal_pos': np.array([goal_pos[0]/6.0, goal_pos[1]/6.0]),
                    'strategic_waypoints': np.array([[p[0]/6.0, p[1]/6.0] for p in strategic_waypoints]),
                    'num_waypoints': len(strategic_waypoints),
                    'path_mode': selected_mode  # ê²½ë¡œ ëª¨ë“œ ì •ë³´ ì¶”ê°€
                }
                
                collected_data.append(data_sample)
                pbar.update(1)
        
        pbar.close()
        
        # ë°ì´í„° ì €ì¥
        save_path = self.output_dir / 'cdif_training_data.json'
        with open(save_path, 'w') as f:
            json.dump(collected_data, f, cls=NumpyEncoder, indent=2)
        
        print(f"âœ… CDIF ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {len(collected_data):,}ê°œ ìƒ˜í”Œ")
        print(f"ğŸ’¾ ì €ì¥ ìœ„ì¹˜: {save_path}")
        
        return collected_data
    
    def _create_integrated_cost_map(self):
        """í†µí•© ë¹„ìš©ë§µ ìƒì„± (3ì±„ë„: ì •ì  + ì‚¬íšŒì  + íë¦„) - 60x60 ê·¸ë¦¬ë“œ"""
        grid_size = 60
        
        # ì±„ë„ 0: ì •ì  ì¥ì• ë¬¼ ë§µ (CGIP ë°©ì‹ - ì´ë¯¸ 60x60)
        static_map = self.simulator.grid.copy().astype(np.float32)
        
        # ì±„ë„ 1: ì‚¬íšŒì  ë¹„ìš©ë§µ (Individual Space ë§µ ìƒì„±)
        social_map = np.zeros((grid_size, grid_size), dtype=np.float32)
        
        # ê° ì—ì´ì „íŠ¸ì— ëŒ€í•´ Individual Space ê³„ì‚°
        for agent in self.simulator.agents:
            if not agent.finished and self.simulator.is_in_cctv_coverage(agent.pos):
                # ê·¸ë¦¬ë“œì˜ ê° ì…€ì— ëŒ€í•´ Individual Space ê°’ ê³„ì‚°
                for i in range(grid_size):
                    for j in range(grid_size):
                        # ê·¸ë¦¬ë“œ ì¢Œí‘œë¥¼ ì‹¤ì œ ì¢Œí‘œë¡œ ë³€í™˜
                        x = (j * self.simulator.grid_size) - 6
                        y = (i * self.simulator.grid_size) - 6
                        
                        # Individual Space ê°’ ê³„ì‚°
                        is_value = agent.calculate_individual_space([x, y])
                        social_map[i, j] = max(social_map[i, j], is_value)
        
        # ì±„ë„ 2: ë³´í–‰ì íë¦„ë§µ (ì†ë„ ì •ë³´)
        flow_map = np.zeros((grid_size, grid_size), dtype=np.float32)
        for agent in self.simulator.agents:
            if hasattr(agent, 'pos') and hasattr(agent, 'velocity'):
                x, y = agent.pos
                vx, vy = agent.velocity
                
                # 60x60 ê·¸ë¦¬ë“œ ì¢Œí‘œë¡œ ë³€í™˜
                x_idx = int((x + 6) / self.simulator.grid_size)
                y_idx = int((y + 6) / self.simulator.grid_size)
                
                if 0 <= x_idx < grid_size and 0 <= y_idx < grid_size:
                    # ì†ë„ í¬ê¸°ë¥¼ íë¦„ ê°•ë„ë¡œ ì‚¬ìš©
                    flow_intensity = min(np.sqrt(vx*vx + vy*vy) / 2.0, 1.0)
                    flow_map[y_idx, x_idx] = max(flow_map[y_idx, x_idx], flow_intensity)
        
        # 3ì±„ë„ í†µí•© [3, 60, 60]
        integrated_map = np.stack([static_map, social_map, flow_map], axis=0)
        return integrated_map
    
    def _generate_safe_position(self, safe_zones):
        """ì•ˆì „í•œ ìœ„ì¹˜ ìƒì„±"""
        for _ in range(50):
            zone = random.choice(safe_zones)
            x = random.uniform(zone[0], zone[2])
            y = random.uniform(zone[1], zone[3])
            
            # ê·¸ë¦¬ë“œ ê¸°ë°˜ ì•ˆì „ì„± ì²´í¬
            x_idx = int((x + 6) / self.simulator.grid_size)
            y_idx = int((y + 6) / self.simulator.grid_size)
            
            if (0 <= x_idx < 60 and 0 <= y_idx < 60 and 
                self.simulator.grid[y_idx, x_idx] == 0):
                return [x, y]
        
        return None

class NumpyEncoder(json.JSONEncoder):
    """NumPy ë°°ì—´ì„ JSONìœ¼ë¡œ ì¸ì½”ë”©"""
    def default(self, obj):
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        return super().default(obj)

class CDIFTrainer:
    """CDIF í•™ìŠµê¸°"""
    
    def __init__(self, config: CDIFConfig, output_dir='models'):
        self.config = config
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        # ë””ë°”ì´ìŠ¤ ì„¤ì •
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ğŸš€ ì‚¬ìš© ë””ë°”ì´ìŠ¤: {self.device}")
        
        if torch.cuda.is_available():
            print(f"GPU: {torch.cuda.get_device_name()}")
            print(f"GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
        
        # ëª¨ë¸ ë° ìŠ¤ì¼€ì¤„ëŸ¬ ì´ˆê¸°í™” (ë‹¤ì¤‘ ê²½ë¡œ ëª¨ë“œ ì§€ì›)
        self.model = CDIFModel(
            max_waypoints=config.max_waypoints,
            feature_dim=config.feature_dim,
            hidden_dim=config.hidden_dim,
            num_layers=config.num_layers,
            num_path_modes=config.num_path_modes
        ).to(self.device)
        
        self.scheduler = DDPMScheduler(
            num_train_timesteps=config.num_train_timesteps,
            beta_schedule=config.beta_schedule
        ).to(self.device)
        
        # ì˜µí‹°ë§ˆì´ì € ì„¤ì •
        self.optimizer = optim.AdamW(
            self.model.parameters(),
            lr=config.learning_rate,
            weight_decay=config.weight_decay
        )
        
        # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬
        self.lr_scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(
            self.optimizer, T_0=10, T_mult=2
        )
        
        # Mixed Precision ì„¤ì •
        self.scaler = torch.cuda.amp.GradScaler() if config.mixed_precision else None
        
        # TensorBoard
        self.writer = SummaryWriter(log_dir=f'runs/cdif_{int(time.time())}')
        
        # í•™ìŠµ ìƒíƒœ
        self.global_step = 0
        self.best_val_loss = float('inf')
        self.patience_counter = 0
        
        print(f"ğŸ“Š ëª¨ë¸ íŒŒë¼ë¯¸í„°: {sum(p.numel() for p in self.model.parameters()):,}")
    
    def train(self, train_data: List[Dict], val_data: List[Dict]):
        """CDIF ëª¨ë¸ í•™ìŠµ"""
        print("ğŸ“ CDIF í•™ìŠµ ì‹œì‘!")
        
        # ë°ì´í„°ì…‹ ìƒì„±
        train_dataset = CDIFDataset(train_data, self.config)
        val_dataset = CDIFDataset(val_data, self.config)
        
        train_loader = DataLoader(
            train_dataset, 
            batch_size=self.config.batch_size,
            shuffle=True,
            num_workers=4,
            pin_memory=True
        )
        
        val_loader = DataLoader(
            val_dataset,
            batch_size=self.config.batch_size,
            shuffle=False,
            num_workers=4,
            pin_memory=True
        )
        
        print(f"ğŸ“š í•™ìŠµ ë°ì´í„°: {len(train_dataset):,}ê°œ")
        print(f"ğŸ“– ê²€ì¦ ë°ì´í„°: {len(val_dataset):,}ê°œ")
        
        # í•™ìŠµ ë£¨í”„
        for epoch in range(self.config.num_epochs):
            # í•™ìŠµ
            train_loss = self._train_epoch(train_loader, epoch)
            
            # ê²€ì¦
            if epoch % self.config.validate_every == 0:
                val_loss = self._validate_epoch(val_loader, epoch)
                
                # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥
                if val_loss < self.best_val_loss:
                    self.best_val_loss = val_loss
                    self.patience_counter = 0
                    self._save_checkpoint(epoch, is_best=True)
                    print(f"ğŸ¯ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! Val Loss: {val_loss:.6f}")
                else:
                    self.patience_counter += 1
                
                # Early stopping
                if self.patience_counter >= self.config.early_stopping_patience:
                    print(f"â° Early stopping at epoch {epoch+1}")
                    break
            
            # ì •ê¸°ì  ì²´í¬í¬ì¸íŠ¸ ì €ì¥
            if epoch % self.config.save_every == 0:
                self._save_checkpoint(epoch)
            
            # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ë§
            self.lr_scheduler.step()
        
        print("âœ… CDIF í•™ìŠµ ì™„ë£Œ!")
        self.writer.close()
    
    def _train_epoch(self, train_loader: DataLoader, epoch: int) -> float:
        """í•œ ì—í¬í¬ í•™ìŠµ"""
        self.model.train()
        total_loss = 0.0
        
        pbar = tqdm(train_loader, desc=f"Epoch {epoch+1} Training")
        
        for batch_idx, batch in enumerate(pbar):
            # ë°ì´í„° GPUë¡œ ì´ë™ (3ì±„ë„ í†µí•© ë¹„ìš©ë§µ)
            integrated_cost_map = batch['integrated_cost_map'].to(self.device)  # [B, 3, 60, 60]
            start_pos = batch['start_pos'].to(self.device)  # [B, 2]
            goal_pos = batch['goal_pos'].to(self.device)  # [B, 2]
            waypoints = batch['waypoints'].to(self.device)  # [B, max_waypoints, 2]
            num_waypoints = batch['num_waypoints'].to(self.device)  # [B]
            path_mode = batch['path_mode'].to(self.device)  # [B]
            
            batch_size = integrated_cost_map.shape[0]
            
            # ëœë¤ íƒ€ì„ìŠ¤í… ìƒì„±
            timesteps = torch.randint(
                0, self.config.num_train_timesteps, 
                (batch_size,), device=self.device
            )
            
            # ì¡ìŒ ìƒì„±
            noise = torch.randn_like(waypoints)
            
            # ì¡ìŒ ì¶”ê°€
            noisy_waypoints = self.scheduler.add_noise(waypoints, noise, timesteps)
            
            # ìˆœì „íŒŒ (ì‚¬íšŒì  ë§¥ë½ ì¸ì‹ ë‹¤ì¤‘ ëª¨ë‹¬)
            with torch.cuda.amp.autocast(enabled=self.config.mixed_precision):
                predicted_noise, mode_probs, num_waypoints_prob = self.model(
                    integrated_cost_map, noisy_waypoints, timesteps, start_pos, goal_pos, path_mode
                )
                
                # ì†ì‹¤ ê³„ì‚°
                noise_loss = F.mse_loss(predicted_noise, noise)
                
                # ê²½ë¡œ ëª¨ë“œ ì˜ˆì¸¡ ì†ì‹¤ (ì‚¬íšŒì  ë§¥ë½ ì¸ì‹)
                mode_targets = F.one_hot(path_mode, num_classes=self.config.num_path_modes).float()
                mode_loss = F.cross_entropy(mode_probs, mode_targets.argmax(dim=1))
                
                # ì›¨ì´í¬ì¸íŠ¸ ìˆ˜ ì˜ˆì¸¡ ì†ì‹¤
                num_targets = F.one_hot(num_waypoints - 1, num_classes=self.config.max_waypoints).float()
                num_loss = F.cross_entropy(num_waypoints_prob, num_targets.argmax(dim=1))
                
                # ì´ ì†ì‹¤ (ì¡ìŒ + ëª¨ë“œ + ì›¨ì´í¬ì¸íŠ¸ ìˆ˜)
                total_loss_batch = noise_loss + 0.2 * mode_loss + 0.1 * num_loss
            
            # ì—­ì „íŒŒ
            self.optimizer.zero_grad()
            
            if self.scaler:
                self.scaler.scale(total_loss_batch).backward()
                self.scaler.unscale_(self.optimizer)
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.gradient_clip)
                self.scaler.step(self.optimizer)
                self.scaler.update()
            else:
                total_loss_batch.backward()
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.gradient_clip)
                self.optimizer.step()
            
            # ì†ì‹¤ ëˆ„ì 
            total_loss += total_loss_batch.item()
            
            # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
            pbar.set_postfix({
                'Loss': f"{total_loss_batch.item():.6f}",
                'Noise': f"{noise_loss.item():.6f}",
                'Mode': f"{mode_loss.item():.6f}",
                'Num': f"{num_loss.item():.6f}"
            })
            
            # TensorBoard ë¡œê¹…
            if self.global_step % 100 == 0:
                self.writer.add_scalar('Train/Loss', total_loss_batch.item(), self.global_step)
                self.writer.add_scalar('Train/NoiseLoss', noise_loss.item(), self.global_step)
                self.writer.add_scalar('Train/NumLoss', num_loss.item(), self.global_step)
                self.writer.add_scalar('Train/LR', self.optimizer.param_groups[0]['lr'], self.global_step)
            
            self.global_step += 1
        
        avg_loss = total_loss / len(train_loader)
        return avg_loss
    
    def _validate_epoch(self, val_loader: DataLoader, epoch: int) -> float:
        """ê²€ì¦"""
        self.model.eval()
        total_loss = 0.0
        
        with torch.no_grad():
            for batch in tqdm(val_loader, desc=f"Epoch {epoch+1} Validation"):
                # ë°ì´í„° GPUë¡œ ì´ë™
                integrated_cost_map = batch['integrated_cost_map'].to(self.device)
                start_pos = batch['start_pos'].to(self.device)
                goal_pos = batch['goal_pos'].to(self.device)
                waypoints = batch['waypoints'].to(self.device)
                num_waypoints = batch['num_waypoints'].to(self.device)
                path_mode = batch['path_mode'].to(self.device)
                
                batch_size = integrated_cost_map.shape[0]
                
                # ëœë¤ íƒ€ì„ìŠ¤í…
                timesteps = torch.randint(
                    0, self.config.num_train_timesteps,
                    (batch_size,), device=self.device
                )
                
                # ì¡ìŒ ì¶”ê°€
                noise = torch.randn_like(waypoints)
                noisy_waypoints = self.scheduler.add_noise(waypoints, noise, timesteps)
                
                # ìˆœì „íŒŒ
                predicted_noise, mode_probs, num_waypoints_prob = self.model(
                    integrated_cost_map, noisy_waypoints, timesteps, start_pos, goal_pos, path_mode
                )
                
                # ì†ì‹¤ ê³„ì‚°
                noise_loss = F.mse_loss(predicted_noise, noise)
                
                mode_targets = F.one_hot(path_mode, num_classes=self.config.num_path_modes).float()
                mode_loss = F.cross_entropy(mode_probs, mode_targets.argmax(dim=1))
                
                num_targets = F.one_hot(num_waypoints - 1, num_classes=self.config.max_waypoints).float()
                num_loss = F.cross_entropy(num_waypoints_prob, num_targets.argmax(dim=1))
                
                total_loss_batch = noise_loss + 0.2 * mode_loss + 0.1 * num_loss
                total_loss += total_loss_batch.item()
        
        avg_loss = total_loss / len(val_loader)
        
        # TensorBoard ë¡œê¹…
        self.writer.add_scalar('Val/Loss', avg_loss, epoch)
        
        print(f"ğŸ“Š Epoch {epoch+1} - Val Loss: {avg_loss:.6f}")
        
        return avg_loss
    
    def _save_checkpoint(self, epoch: int, is_best: bool = False):
        """ì²´í¬í¬ì¸íŠ¸ ì €ì¥"""
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.lr_scheduler.state_dict(),
            'best_val_loss': self.best_val_loss,
            'config': self.config,
            'global_step': self.global_step
        }
        
        if is_best:
            save_path = self.output_dir / 'cdif_best.pth'
            torch.save(checkpoint, save_path)
            print(f"ğŸ’¾ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥: {save_path}")
        
        # ì •ê¸°ì  ì²´í¬í¬ì¸íŠ¸
        save_path = self.output_dir / f'cdif_epoch_{epoch+1}.pth'
        torch.save(checkpoint, save_path)

def main():
    parser = argparse.ArgumentParser(description='CDIF Training')
    parser.add_argument('--config', type=str, help='Config file path')
    parser.add_argument('--data_only', action='store_true', help='Only collect data')
    parser.add_argument('--resume', type=str, help='Resume from checkpoint')
    args = parser.parse_args()
    
    # ì„¤ì • ë¡œë“œ
    config = CDIFConfig()
    
    print("ğŸš€ CDIF í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹œì‘!")
    print(f"âš™ï¸  ì„¤ì •: {config}")
    
    # 1. ë°ì´í„° ìˆ˜ì§‘
    collector = CDIFDataCollector(config)
    
    # ê¸°ì¡´ ë°ì´í„° í™•ì¸
    data_path = collector.output_dir / 'cdif_training_data.json'
    if data_path.exists():
        print(f"ğŸ“‚ ê¸°ì¡´ ë°ì´í„° ë¡œë“œ: {data_path}")
        with open(data_path, 'r') as f:
            all_data = json.load(f)
    else:
        print("ğŸ“Š ìƒˆë¡œìš´ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
        all_data = collector.collect_data()
    
    if args.data_only:
        print("âœ… ë°ì´í„° ìˆ˜ì§‘ë§Œ ì™„ë£Œ!")
        return
    
    # 2. ë°ì´í„° ë¶„í• 
    random.shuffle(all_data)
    split_idx = int(len(all_data) * config.train_ratio)
    train_data = all_data[:split_idx]
    val_data = all_data[split_idx:]
    
    print(f"ğŸ“š í•™ìŠµ/ê²€ì¦ ë°ì´í„° ë¶„í• : {len(train_data)}/{len(val_data)}")
    
    # 3. í•™ìŠµ
    trainer = CDIFTrainer(config)
    
    if args.resume:
        print(f"ğŸ”„ ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ê°œ: {args.resume}")
        checkpoint = torch.load(args.resume)
        trainer.model.load_state_dict(checkpoint['model_state_dict'])
        trainer.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        trainer.lr_scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
        trainer.best_val_loss = checkpoint['best_val_loss']
        trainer.global_step = checkpoint['global_step']
    
    trainer.train(train_data, val_data)

if __name__ == "__main__":
    main() 