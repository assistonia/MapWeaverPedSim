#!/usr/bin/env python3
"""
ì „ëµì  ì›¨ì´í¬ì¸íŠ¸ ê¸°ë°˜ DiPPeR í•™ìŠµ
- ë³‘ëª©ì§€ì  ì¤‘ì‹¬ ê²½ë¡œ ê³„íš
- ìµœì†Œí•œì˜ í•µì‹¬ ì›¨ì´í¬ì¸íŠ¸ (5-10ê°œ)
- ë¡œì»¬ ì—ì´ì „íŠ¸ì™€ì˜ ì—­í•  ë¶„ë‹´
"""

import os
import sys
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
from tqdm import tqdm
import json
from pathlib import Path
import random
import cv2
from scipy.ndimage import binary_dilation, distance_transform_edt

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from robot_simuator_dippeR import RobotSimulatorDiPPeR

class StrategicWaypointExtractor:
    """ì „ëµì  ì›¨ì´í¬ì¸íŠ¸ ì¶”ì¶œê¸°"""
    
    def __init__(self, grid_size=0.2):
        self.grid_size = grid_size
        
    def extract_strategic_waypoints(self, start_pos, goal_pos, cost_map, max_waypoints=8):
        """ë³‘ëª©ì§€ì  ê¸°ë°˜ ì „ëµì  ì›¨ì´í¬ì¸íŠ¸ ì¶”ì¶œ"""
        
        # 1. ë³‘ëª©ì§€ì  íƒì§€
        bottlenecks = self._detect_bottlenecks(cost_map)
        
        # 2. A* ê¸°ë³¸ ê²½ë¡œ
        simulator = RobotSimulatorDiPPeR('scenarios/Circulation1.xml', model_path=None)
        astar_path = simulator.fallback_astar_planning(start_pos, goal_pos)
        
        if not astar_path or len(astar_path) < 2:
            return [start_pos, goal_pos]
        
        # 3. ê²½ë¡œ ìƒì˜ ì¤‘ìš” ì§€ì  ì‹ë³„
        critical_points = self._identify_critical_points(astar_path, bottlenecks, cost_map)
        
        # 4. ì „ëµì  ì›¨ì´í¬ì¸íŠ¸ ì„ íƒ
        strategic_waypoints = self._select_strategic_waypoints(
            start_pos, goal_pos, critical_points, max_waypoints
        )
        
        return strategic_waypoints
    
    def _detect_bottlenecks(self, cost_map):
        """ë³‘ëª©ì§€ì  íƒì§€"""
        # ì¥ì• ë¬¼ ë§µ (ë†’ì€ ë¹„ìš© = ì¥ì• ë¬¼)
        obstacle_map = (cost_map > 0.5).astype(np.uint8)
        
        # ììœ  ê³µê°„
        free_space = 1 - obstacle_map
        
        # ê±°ë¦¬ ë³€í™˜ (ì¥ì• ë¬¼ë¡œë¶€í„°ì˜ ê±°ë¦¬)
        distance_map = distance_transform_edt(free_space)
        
        # ë³‘ëª©ì§€ì : ê±°ë¦¬ê°€ ì‘ì§€ë§Œ 0ì´ ì•„ë‹Œ ì§€ì  (ì¢ì€ í†µë¡œ)
        bottleneck_threshold = 3.0  # 0.6m ì´í•˜ì˜ ì¢ì€ í†µë¡œ
        bottlenecks = (distance_map > 0) & (distance_map < bottleneck_threshold)
        
        return bottlenecks
    
    def _identify_critical_points(self, astar_path, bottlenecks, cost_map):
        """ê²½ë¡œ ìƒì˜ ì¤‘ìš” ì§€ì  ì‹ë³„"""
        critical_points = []
        
        for i, point in enumerate(astar_path):
            # ê²©ì ì¢Œí‘œë¡œ ë³€í™˜
            x_idx = int((point[0] + 6) / self.grid_size)
            y_idx = int((point[1] + 6) / self.grid_size)
            
            if 0 <= x_idx < 60 and 0 <= y_idx < 60:
                # ë³‘ëª©ì§€ì  ê·¼ì²˜ì¸ì§€ í™•ì¸
                if bottlenecks[y_idx, x_idx]:
                    critical_points.append({
                        'point': point,
                        'index': i,
                        'type': 'bottleneck',
                        'importance': 1.0
                    })
                
                # ë°©í–¥ ê¸‰ë³€ ì§€ì 
                if i > 0 and i < len(astar_path) - 1:
                    v1 = np.array(astar_path[i]) - np.array(astar_path[i-1])
                    v2 = np.array(astar_path[i+1]) - np.array(astar_path[i])
                    
                    if np.linalg.norm(v1) > 0 and np.linalg.norm(v2) > 0:
                        cos_angle = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))
                        angle = np.arccos(np.clip(cos_angle, -1, 1))
                        
                        # 45ë„ ì´ìƒ ë°©í–¥ ë³€ê²½
                        if angle > np.pi / 4:
                            critical_points.append({
                                'point': point,
                                'index': i,
                                'type': 'turn',
                                'importance': angle / np.pi
                            })
                
                # ë†’ì€ ë¹„ìš© ì§€ì—­ í†µê³¼
                if cost_map[y_idx, x_idx] > 0.3:
                    critical_points.append({
                        'point': point,
                        'index': i,
                        'type': 'high_cost',
                        'importance': cost_map[y_idx, x_idx]
                    })
        
        return critical_points
    
    def _select_strategic_waypoints(self, start_pos, goal_pos, critical_points, max_waypoints):
        """ì „ëµì  ì›¨ì´í¬ì¸íŠ¸ ì„ íƒ"""
        waypoints = [start_pos]
        
        if not critical_points:
            waypoints.append(goal_pos)
            return waypoints
        
        # ì¤‘ìš”ë„ ìˆœìœ¼ë¡œ ì •ë ¬
        critical_points.sort(key=lambda x: x['importance'], reverse=True)
        
        # ê²½ë¡œ ìˆœì„œ ìœ ì§€í•˜ë©´ì„œ ì„ íƒ
        selected_indices = set()
        for cp in critical_points:
            if len(selected_indices) >= max_waypoints - 2:  # ì‹œì‘/ëì  ì œì™¸
                break
            selected_indices.add(cp['index'])
        
        # ì¸ë±ìŠ¤ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ê²½ë¡œ ìˆœì„œ ìœ ì§€
        selected_indices = sorted(selected_indices)
        
        # ì›¨ì´í¬ì¸íŠ¸ ì¶”ê°€
        for idx in selected_indices:
            for cp in critical_points:
                if cp['index'] == idx:
                    waypoints.append(cp['point'])
                    break
        
        waypoints.append(goal_pos)
        
        # ì¤‘ë³µ ì œê±° ë° ê±°ë¦¬ ì²´í¬
        final_waypoints = [waypoints[0]]
        for i in range(1, len(waypoints)):
            dist = np.linalg.norm(np.array(waypoints[i]) - np.array(final_waypoints[-1]))
            if dist > 1.0:  # 1m ì´ìƒ ë–¨ì–´ì§„ ì ë§Œ ì¶”ê°€
                final_waypoints.append(waypoints[i])
        
        # ë§ˆì§€ë§‰ ì ì´ ëª©í‘œì ì´ ì•„ë‹ˆë©´ ì¶”ê°€
        if np.linalg.norm(np.array(final_waypoints[-1]) - np.array(goal_pos)) > 0.5:
            final_waypoints.append(goal_pos)
        
        return final_waypoints

class StrategicDataset(Dataset):
    """ì „ëµì  ì›¨ì´í¬ì¸íŠ¸ ë°ì´í„°ì…‹"""
    
    def __init__(self, data_dir='training_data_strategic'):
        self.data_dir = Path(data_dir)
        self.samples = []
        self._load_data()
        
    def _load_data(self):
        """ë°ì´í„° ë¡œë“œ"""
        data_files = list(self.data_dir.glob('*.json'))
        
        for file_path in tqdm(data_files, desc="ë°ì´í„° ë¡œë”©"):
            try:
                with open(file_path, 'r') as f:
                    data = json.load(f)
                    if isinstance(data, list):
                        self.samples.extend(data)
                    else:
                        self.samples.append(data)
            except Exception as e:
                print(f"íŒŒì¼ ë¡œë”© ì‹¤íŒ¨ {file_path}: {e}")
        
        print(f"ì´ {len(self.samples)}ê°œ ìƒ˜í”Œ ë¡œë“œ ì™„ë£Œ")
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        sample = self.samples[idx]
        
        # í…ì„œ ë³€í™˜
        cost_map = torch.from_numpy(np.array(sample['cost_map'])).float().unsqueeze(0)
        start_pos = torch.from_numpy(np.array(sample['start_pos'])).float()
        goal_pos = torch.from_numpy(np.array(sample['goal_pos'])).float()
        
        # ê°€ë³€ ê¸¸ì´ ì›¨ì´í¬ì¸íŠ¸ë¥¼ ê³ ì • ê¸¸ì´ë¡œ íŒ¨ë”©
        waypoints = sample['strategic_waypoints']
        max_waypoints = 10
        
        if len(waypoints) > max_waypoints:
            waypoints = waypoints[:max_waypoints]
        else:
            # íŒ¨ë”©: ë§ˆì§€ë§‰ ì ìœ¼ë¡œ ì±„ì›€
            while len(waypoints) < max_waypoints:
                waypoints.append(waypoints[-1])
        
        waypoints_tensor = torch.from_numpy(np.array(waypoints)).float()
        num_valid = torch.tensor(len(sample['strategic_waypoints']), dtype=torch.long)
        
        return cost_map, start_pos, goal_pos, waypoints_tensor, num_valid

class StrategicDiPPeR(nn.Module):
    """ì „ëµì  ì›¨ì´í¬ì¸íŠ¸ ìƒì„± ëª¨ë¸"""
    
    def __init__(self, max_waypoints=10):
        super().__init__()
        self.max_waypoints = max_waypoints
        
        # CNN ë°±ë³¸ (ë¹„ìš© ë§µ ì²˜ë¦¬)
        self.cnn = nn.Sequential(
            nn.Conv2d(1, 32, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(32, 64, 3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2),  # 60x60 -> 30x30
            
            nn.Conv2d(64, 128, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(128, 256, 3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2),  # 30x30 -> 15x15
            
            nn.AdaptiveAvgPool2d(8),  # 15x15 -> 8x8
            nn.Flatten()
        )
        
        # ì‹œì‘/ëª©í‘œì  ì¸ì½”ë”
        self.pos_encoder = nn.Sequential(
            nn.Linear(4, 64),
            nn.ReLU(),
            nn.Linear(64, 128),
            nn.ReLU()
        )
        
        # ìœµí•© ë° ì›¨ì´í¬ì¸íŠ¸ ìƒì„±
        cnn_out_size = 256 * 8 * 8
        self.fusion = nn.Sequential(
            nn.Linear(cnn_out_size + 128, 512),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.Dropout(0.2)
        )
        
        # ì›¨ì´í¬ì¸íŠ¸ ìˆ˜ ì˜ˆì¸¡
        self.num_predictor = nn.Sequential(
            nn.Linear(256, 64),
            nn.ReLU(),
            nn.Linear(64, max_waypoints),
            nn.Softmax(dim=-1)
        )
        
        # ì›¨ì´í¬ì¸íŠ¸ ì¢Œí‘œ ì˜ˆì¸¡
        self.waypoint_predictor = nn.Sequential(
            nn.Linear(256, max_waypoints * 2),
            nn.Tanh()  # -1 ~ 1 ë²”ìœ„
        )
    
    def forward(self, cost_map, start_pos, goal_pos):
        # ë¹„ìš© ë§µ íŠ¹ì§• ì¶”ì¶œ
        cnn_features = self.cnn(cost_map)
        
        # ì‹œì‘/ëª©í‘œì  ì¸ì½”ë”©
        start_goal = torch.cat([start_pos, goal_pos], dim=-1)
        pos_features = self.pos_encoder(start_goal)
        
        # íŠ¹ì§• ìœµí•©
        fused = torch.cat([cnn_features, pos_features], dim=-1)
        fused_features = self.fusion(fused)
        
        # ì›¨ì´í¬ì¸íŠ¸ ìˆ˜ ì˜ˆì¸¡
        num_waypoints_prob = self.num_predictor(fused_features)
        
        # ì›¨ì´í¬ì¸íŠ¸ ì¢Œí‘œ ì˜ˆì¸¡
        waypoints_flat = self.waypoint_predictor(fused_features)
        waypoints = waypoints_flat.view(-1, self.max_waypoints, 2)
        
        return waypoints, num_waypoints_prob

class StrategicDataCollector:
    """ì „ëµì  ì›¨ì´í¬ì¸íŠ¸ ë°ì´í„° ìˆ˜ì§‘ê¸°"""
    
    def __init__(self, xml_file, output_dir='training_data_strategic'):
        self.simulator = RobotSimulatorDiPPeR(xml_file, model_path=None)
        self.simulator.use_dipperp = False
        self.extractor = StrategicWaypointExtractor()
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
    def collect_strategic_data(self, target_samples=10000):
        """ì „ëµì  ì›¨ì´í¬ì¸íŠ¸ ë°ì´í„° ìˆ˜ì§‘"""
        print(f"ğŸ¯ ëª©í‘œ: {target_samples:,}ê°œ ì „ëµì  ê²½ë¡œ ìˆ˜ì§‘")
        
        collected_data = []
        batch_size = 500
        batch_count = 0
        
        pbar = tqdm(total=target_samples, desc="ì „ëµì  ë°ì´í„° ìˆ˜ì§‘")
        
        while len(collected_data) < target_samples:
            # ëœë¤ ì‹œì‘/ëª©í‘œì 
            start_pos = self._generate_safe_position()
            goal_pos = self._generate_safe_position()
            
            if start_pos is None or goal_pos is None:
                continue
            
            # ê±°ë¦¬ ì²´í¬
            dist = np.linalg.norm(np.array(start_pos) - np.array(goal_pos))
            if dist < 3.0:  # ìµœì†Œ 3m ì´ìƒ
                continue
            
            # ì „ëµì  ì›¨ì´í¬ì¸íŠ¸ ì¶”ì¶œ
            strategic_waypoints = self.extractor.extract_strategic_waypoints(
                start_pos, goal_pos, self.simulator.fused_cost_map
            )
            
            if len(strategic_waypoints) >= 2:
                data_sample = {
                    'cost_map': self.simulator.fused_cost_map.copy(),
                    'start_pos': np.array([start_pos[0]/6.0, start_pos[1]/6.0]),  # ì •ê·œí™”
                    'goal_pos': np.array([goal_pos[0]/6.0, goal_pos[1]/6.0]),    # ì •ê·œí™”
                    'strategic_waypoints': np.array([[p[0]/6.0, p[1]/6.0] for p in strategic_waypoints]),
                    'num_waypoints': len(strategic_waypoints)
                }
                
                collected_data.append(data_sample)
                pbar.update(1)
            
            # ë°°ì¹˜ ì €ì¥
            if len(collected_data) >= batch_size:
                self._save_batch(collected_data[:batch_size], batch_count)
                collected_data = collected_data[batch_size:]
                batch_count += 1
        
        # ë‚¨ì€ ë°ì´í„° ì €ì¥
        if collected_data:
            self._save_batch(collected_data, batch_count)
        
        pbar.close()
        print(f"âœ… ì „ëµì  ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {batch_count + 1}ê°œ ë°°ì¹˜ íŒŒì¼")
    
    def _generate_safe_position(self):
        """ì•ˆì „í•œ ìœ„ì¹˜ ìƒì„±"""
        safe_zones = [
            (-5.5, -5.5, -0.5, -0.5),
            (-5.5, 0.5, -0.5, 5.5),
            (0.5, -5.5, 5.5, -0.5),
            (0.5, 0.5, 5.5, 5.5),
            (-2.0, -2.0, 2.0, 2.0)
        ]
        
        for _ in range(50):
            zone = random.choice(safe_zones)
            x = random.uniform(zone[0], zone[2])
            y = random.uniform(zone[1], zone[3])
            
            if self.simulator.is_position_safe([x, y]):
                return [x, y]
        
        return None
    
    def _save_batch(self, data, batch_id):
        """ë°°ì¹˜ ë°ì´í„° ì €ì¥"""
        filename = self.output_dir / f"strategic_batch_{batch_id:04d}.json"
        with open(filename, 'w') as f:
            json.dump(data, f, cls=NumpyEncoder)
        print(f"ì „ëµì  ë°°ì¹˜ ì €ì¥: {filename} ({len(data)}ê°œ ìƒ˜í”Œ)")

class NumpyEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        return super().default(obj)

def train_strategic_dipperp():
    """ì „ëµì  DiPPeR í•™ìŠµ"""
    print("=== ì „ëµì  ì›¨ì´í¬ì¸íŠ¸ DiPPeR í•™ìŠµ ===")
    
    # 1. ë°ì´í„° ìˆ˜ì§‘
    print("\n1. ì „ëµì  ë°ì´í„° ìˆ˜ì§‘...")
    collector = StrategicDataCollector('scenarios/Circulation1.xml')
    collector.collect_strategic_data(target_samples=5000)
    
    # 2. ë°ì´í„°ì…‹ ë¡œë“œ
    print("\n2. ë°ì´í„°ì…‹ ë¡œë“œ...")
    dataset = StrategicDataset('training_data_strategic')
    
    train_size = int(0.9 * len(dataset))
    val_size = len(dataset) - train_size
    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])
    
    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)
    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)
    
    print(f"í•™ìŠµ ë°ì´í„°: {len(train_dataset):,}ê°œ")
    print(f"ê²€ì¦ ë°ì´í„°: {len(val_dataset):,}ê°œ")
    
    # 3. ëª¨ë¸ ë° ì˜µí‹°ë§ˆì´ì €
    print("\n3. ì „ëµì  ëª¨ë¸ ìƒì„±...")
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = StrategicDiPPeR(max_waypoints=10).to(device)
    
    optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-5)
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)
    
    # ì†ì‹¤ í•¨ìˆ˜
    mse_loss = nn.MSELoss()
    ce_loss = nn.CrossEntropyLoss()
    
    # 4. í•™ìŠµ
    print("\n4. ì „ëµì  í•™ìŠµ ì‹œì‘...")
    os.makedirs('models', exist_ok=True)
    
    best_loss = float('inf')
    patience = 15
    patience_counter = 0
    
    for epoch in range(100):
        # í•™ìŠµ
        model.train()
        train_loss = 0
        
        for batch in tqdm(train_loader, desc=f"Epoch {epoch+1}"):
            cost_maps, start_pos, goal_pos, waypoints_gt, num_valid = batch
            cost_maps = cost_maps.to(device)
            start_pos = start_pos.to(device)
            goal_pos = goal_pos.to(device)
            waypoints_gt = waypoints_gt.to(device)
            num_valid = num_valid.to(device)
            
            optimizer.zero_grad()
            
            # ì˜ˆì¸¡
            waypoints_pred, num_pred = model(cost_maps, start_pos, goal_pos)
            
            # ì†ì‹¤ ê³„ì‚°
            waypoint_loss = mse_loss(waypoints_pred, waypoints_gt)
            
            # ì›¨ì´í¬ì¸íŠ¸ ìˆ˜ ì˜ˆì¸¡ ì†ì‹¤
            num_targets = torch.zeros(num_valid.size(0), 10, device=device)
            for i, n in enumerate(num_valid):
                if n < 10:
                    num_targets[i, n-1] = 1.0  # ì¸ë±ìŠ¤ëŠ” 0ë¶€í„°
            
            num_loss = ce_loss(num_pred, num_targets.argmax(dim=1))
            
            total_loss = waypoint_loss + 0.1 * num_loss
            
            total_loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
            optimizer.step()
            
            train_loss += total_loss.item()
        
        # ê²€ì¦
        model.eval()
        val_loss = 0
        with torch.no_grad():
            for batch in val_loader:
                cost_maps, start_pos, goal_pos, waypoints_gt, num_valid = batch
                cost_maps = cost_maps.to(device)
                start_pos = start_pos.to(device)
                goal_pos = goal_pos.to(device)
                waypoints_gt = waypoints_gt.to(device)
                num_valid = num_valid.to(device)
                
                waypoints_pred, num_pred = model(cost_maps, start_pos, goal_pos)
                
                waypoint_loss = mse_loss(waypoints_pred, waypoints_gt)
                num_targets = torch.zeros(num_valid.size(0), 10, device=device)
                for i, n in enumerate(num_valid):
                    if n < 10:
                        num_targets[i, n-1] = 1.0
                
                num_loss = ce_loss(num_pred, num_targets.argmax(dim=1))
                total_loss = waypoint_loss + 0.1 * num_loss
                
                val_loss += total_loss.item()
        
        train_loss /= len(train_loader)
        val_loss /= len(val_loader)
        
        print(f"Epoch {epoch+1}: Train Loss = {train_loss:.6f}, Val Loss = {val_loss:.6f}")
        
        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥
        if val_loss < best_loss:
            best_loss = val_loss
            patience_counter = 0
            torch.save(model.state_dict(), 'models/strategic_dipperp_best.pth')
            print(f"ğŸ¯ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥: {val_loss:.6f}")
        else:
            patience_counter += 1
        
        # Early stopping
        if patience_counter >= patience:
            print(f"Early stopping at epoch {epoch+1}")
            break
        
        scheduler.step()
    
    print("âœ… ì „ëµì  DiPPeR í•™ìŠµ ì™„ë£Œ!")

if __name__ == "__main__":
    train_strategic_dipperp() 