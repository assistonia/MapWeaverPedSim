#!/usr/bin/env python3
"""
DiPPeR ëª¨ë¸ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
1. ì •ì„±ì  í‰ê°€: ì‹œê°ì  ê²½ë¡œ í’ˆì§ˆ ê²€ì¦
2. ì •ëŸ‰ì  í‰ê°€: ì„±ëŠ¥ ì§€í‘œ ì¸¡ì •
"""

import torch
import numpy as np
import matplotlib.pyplot as plt
import json
import time
from pathlib import Path
import argparse
from tqdm import tqdm
import pandas as pd

from robot_simuator_dippeR import RobotSimulatorDiPPeR, DiPPeR
from train_dipperp import SimulationDataCollector

class DiPPeRValidator:
    """DiPPeR ëª¨ë¸ ê²€ì¦ í´ë˜ìŠ¤"""
    
    def __init__(self, model_path, xml_file):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # DiPPeR ëª¨ë¸ ë¡œë“œ
        self.dipperp_model = DiPPeR(visual_feature_dim=512, path_dim=2, max_timesteps=1000)
        if Path(model_path).exists():
            checkpoint = torch.load(model_path, map_location=self.device)
            if 'model_state_dict' in checkpoint:
                # í•™ìŠµ ì‹œ ì €ì¥ëœ ì²´í¬í¬ì¸íŠ¸ í˜•ì‹
                self.dipperp_model.load_state_dict(checkpoint['model_state_dict'])
            else:
                # ë‹¨ìˆœ ëª¨ë¸ ìƒíƒœë§Œ ì €ì¥ëœ í˜•ì‹
                self.dipperp_model.load_state_dict(checkpoint)
            print(f"âœ… DiPPeR ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_path}")
        else:
            print(f"âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {model_path}")
            return
            
        self.dipperp_model.to(self.device)
        self.dipperp_model.eval()
        
        # ì‹œë®¬ë ˆì´í„° ì´ˆê¸°í™” (ë¹„êµìš© A* í¬í•¨)
        self.simulator = RobotSimulatorDiPPeR(xml_file, model_path=None)
        self.simulator.use_dipperp = False  # A* ì‚¬ìš©
        
        # ê²°ê³¼ ì €ì¥ìš©
        self.results = {
            'qualitative': [],
            'quantitative': []
        }
    
    def collect_test_scenarios(self, num_scenarios=50):
        """ë‹¤ì–‘í•œ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ìˆ˜ì§‘"""
        print(f"ğŸ” {num_scenarios}ê°œ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ìˆ˜ì§‘ ì¤‘...")
        
        scenarios = []
        
        for i in tqdm(range(num_scenarios), desc="ì‹œë‚˜ë¦¬ì˜¤ ìˆ˜ì§‘"):
            # ëœë¤ ì‹œì‘/ëª©í‘œì  ìƒì„±
            start_pos = self._generate_safe_position()
            goal_pos = self._generate_safe_position()
            
            # ìµœì†Œ ê±°ë¦¬ ë³´ì¥
            while np.linalg.norm(np.array(start_pos) - np.array(goal_pos)) < 2.0:
                goal_pos = self._generate_safe_position()
            
            # ì‹œë®¬ë ˆì´í„° ìƒíƒœ ì„¤ì •
            self.simulator.robot_pos = start_pos.copy()
            self.simulator.target_pos = goal_pos.copy()
            
            # ëª‡ ìŠ¤í… ì§„í–‰í•˜ì—¬ ë™ì  ìƒí™© ìƒì„±
            for _ in range(np.random.randint(10, 30)):
                self.simulator.update()
            
            # í˜„ì¬ ìƒíƒœ ìº¡ì²˜
            self.simulator.update_fused_cost_map()
            scenario = {
                'id': i,
                'start_pos': start_pos,
                'goal_pos': goal_pos,
                'fused_cost_map': self.simulator.fused_cost_map.copy(),
                'agent_positions': [(agent.pos[0], agent.pos[1]) for agent in self.simulator.agents]
            }
            scenarios.append(scenario)
        
        print(f"âœ… {len(scenarios)}ê°œ ì‹œë‚˜ë¦¬ì˜¤ ìˆ˜ì§‘ ì™„ë£Œ")
        return scenarios
    
    def _generate_safe_position(self):
        """ì•ˆì „í•œ ìœ„ì¹˜ ìƒì„±"""
        safe_zones = [
            (-4.5, -0.5, -4.5, 1.5),   # ì™¼ìª½ ìœ„
            (-4.5, -0.5, -2.0, -1.5),  # ì™¼ìª½ ì•„ë˜
            (2.5, 3.5, -4.5, -0.5),    # ì˜¤ë¥¸ìª½ ì•„ë˜
            (2.5, 3.5, 1.0, 2.0),      # ì˜¤ë¥¸ìª½ ìœ„
            (-0.5, 1.5, 3.0, 4.5)      # ìœ„ìª½ ì¤‘ì•™
        ]
        
        for _ in range(50):
            zone = safe_zones[np.random.randint(len(safe_zones))]
            pos = [np.random.uniform(zone[0], zone[1]), 
                   np.random.uniform(zone[2], zone[3])]
            if self.simulator.is_position_safe(pos):
                return pos
        
        return [0.0, 0.0]  # í´ë°±
    
    def qualitative_evaluation(self, scenarios, save_dir="evaluation_results"):
        """ì •ì„±ì  í‰ê°€: ì‹œê°ì  ê²€ì¦"""
        print("ğŸ¨ ì •ì„±ì  í‰ê°€ ì‹œì‘...")
        
        Path(save_dir).mkdir(exist_ok=True)
        qualitative_results = []
        
        for i, scenario in enumerate(tqdm(scenarios[:10], desc="ì‹œê°ì  ê²€ì¦")):  # ì²˜ìŒ 10ê°œë§Œ
            # DiPPeR ê²½ë¡œ ìƒì„±
            dipperp_path = self._generate_dipperp_path(scenario)
            
            # A* ê²½ë¡œ ìƒì„± (ë¹„êµìš©)
            astar_path = self.simulator.fallback_astar_planning(
                scenario['start_pos'], scenario['goal_pos']
            )
            
            # ì‹œê°í™”
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))
            
            # DiPPeR ê²°ê³¼
            self._plot_path_comparison(ax1, scenario, dipperp_path, "DiPPeR Path")
            
            # A* ê²°ê³¼
            self._plot_path_comparison(ax2, scenario, astar_path, "A* Path")
            
            plt.suptitle(f"Scenario {i}: Start{scenario['start_pos']} â†’ Goal{scenario['goal_pos']}")
            plt.tight_layout()
            plt.savefig(f"{save_dir}/scenario_{i:03d}.png", dpi=150, bbox_inches='tight')
            plt.close()
            
            # ì •ì„±ì  ì§€í‘œ ê³„ì‚°
            quality_metrics = self._calculate_path_quality(scenario, dipperp_path, astar_path)
            qualitative_results.append(quality_metrics)
        
        self.results['qualitative'] = qualitative_results
        print(f"âœ… ì •ì„±ì  í‰ê°€ ì™„ë£Œ. ê²°ê³¼ ì €ì¥: {save_dir}/")
        
        return qualitative_results
    
    def _generate_dipperp_path(self, scenario):
        """DiPPeRë¡œ ê²½ë¡œ ìƒì„± (ì•ˆì „ì„± ê²€ì¦ í¬í•¨)"""
        try:
            # Fused Cost Mapì„ í…ì„œë¡œ ë³€í™˜
            cost_map = torch.from_numpy(scenario['fused_cost_map']).float()
            cost_map = cost_map.unsqueeze(0).unsqueeze(0).to(self.device) / 255.0  # ì •ê·œí™”
            
            # ì‹œì‘/ëª©í‘œì  ì •ê·œí™”
            start_norm = torch.tensor([[scenario['start_pos'][0]/6.0, scenario['start_pos'][1]/6.0]], 
                                    dtype=torch.float32, device=self.device)
            goal_norm = torch.tensor([[scenario['goal_pos'][0]/6.0, scenario['goal_pos'][1]/6.0]], 
                                   dtype=torch.float32, device=self.device)
            
            # DiPPeR ê²½ë¡œ ìƒì„±
            with torch.no_grad():
                generated_path = self.dipperp_model.sample_path(
                    cost_map, start_norm, goal_norm, 
                    path_length=50, num_inference_steps=20
                )
            
            # ì‹¤ì œ ì¢Œí‘œë¡œ ë³€í™˜
            path_real = generated_path[0].cpu().numpy() * 6.0
            path_list = [[float(point[0]), float(point[1])] for point in path_real]
            
            # ê²½ë¡œ ì•ˆì „ì„± ê²€ì¦ ë° ìˆ˜ì • (ì‹¤ì œ ì‹œë®¬ë ˆì´í„°ì™€ ë™ì¼í•œ ë¡œì§)
            safe_path = []
            for i, point in enumerate(path_list):
                if self.simulator.is_position_safe(point):
                    safe_path.append(point)
                else:
                    # ìœ„í—˜í•œ ì›¨ì´í¬ì¸íŠ¸ ê°ì§€ ì‹œ A* ë³´ì • ì ìš©
                    if safe_path:
                        prev_safe = safe_path[-1]
                        # ë‹¤ìŒ ì•ˆì „í•œ ì  ì°¾ê¸°
                        next_safe = None
                        for j in range(i+1, len(path_list)):
                            if self.simulator.is_position_safe(path_list[j]):
                                next_safe = path_list[j]
                                break
                        
                        if next_safe:
                            # A*ë¡œ ì•ˆì „í•œ ê²½ë¡œ ìƒì„±
                            correction_path = self.simulator.fallback_astar_planning(prev_safe, next_safe)
                            if correction_path and len(correction_path) > 2:
                                # ì¤‘ê°„ ì ë“¤ë§Œ ì¶”ê°€ (ì‹œì‘ì , ëì  ì œì™¸)
                                safe_path.extend(correction_path[1:-1])
                        
                        if next_safe:
                            safe_path.append(next_safe)
                    else:
                        # ì²« ë²ˆì§¸ ì ì´ ìœ„í—˜í•˜ë©´ ì‹œì‘ì  ì‚¬ìš©
                        safe_path.append(scenario['start_pos'])
            
            # ì•ˆì „ì„± ê²€ì¦ëœ ê²½ë¡œê°€ ë„ˆë¬´ ì§§ìœ¼ë©´ A* í´ë°±
            if len(safe_path) < 5:
                return self.simulator.fallback_astar_planning(
                    scenario['start_pos'], scenario['goal_pos']
                )
            
            return safe_path
            
        except Exception as e:
            print(f"DiPPeR ê²½ë¡œ ìƒì„± ì‹¤íŒ¨: {e}")
            # í´ë°±: A* ì‚¬ìš©
            return self.simulator.fallback_astar_planning(
                scenario['start_pos'], scenario['goal_pos']
            )
    
    def _plot_path_comparison(self, ax, scenario, path, title):
        """ê²½ë¡œ ë¹„êµ ì‹œê°í™”"""
        # Fused Cost Map í‘œì‹œ
        ax.imshow(scenario['fused_cost_map'], extent=[-6, 6, -6, 6], 
                 origin='lower', cmap='hot', alpha=0.7)
        
        # ì—ì´ì „íŠ¸ ìœ„ì¹˜
        for agent_pos in scenario['agent_positions']:
            ax.plot(agent_pos[0], agent_pos[1], 'bo', markersize=8, alpha=0.8)
        
        # ê²½ë¡œ í‘œì‹œ
        if path and len(path) > 1:
            path_array = np.array(path)
            ax.plot(path_array[:, 0], path_array[:, 1], 'g-', linewidth=3, alpha=0.8)
            ax.plot(path_array[:, 0], path_array[:, 1], 'g.', markersize=4)
        
        # ì‹œì‘/ëª©í‘œì 
        ax.plot(scenario['start_pos'][0], scenario['start_pos'][1], 'rs', markersize=12, label='Start')
        ax.plot(scenario['goal_pos'][0], scenario['goal_pos'][1], 'r^', markersize=12, label='Goal')
        
        ax.set_xlim(-6, 6)
        ax.set_ylim(-6, 6)
        ax.set_title(title)
        ax.legend()
        ax.grid(True, alpha=0.3)
    
    def quantitative_evaluation(self, scenarios):
        """ì •ëŸ‰ì  í‰ê°€: ì„±ëŠ¥ ì§€í‘œ ì¸¡ì •"""
        print("ğŸ“Š ì •ëŸ‰ì  í‰ê°€ ì‹œì‘...")
        
        quantitative_results = []
        
        for scenario in tqdm(scenarios, desc="ì •ëŸ‰ì  í‰ê°€"):
            # ì‹œê°„ ì¸¡ì •
            start_time = time.time()
            dipperp_path = self._generate_dipperp_path(scenario)
            dipperp_time = time.time() - start_time
            
            start_time = time.time()
            astar_path = self.simulator.fallback_astar_planning(
                scenario['start_pos'], scenario['goal_pos']
            )
            astar_time = time.time() - start_time
            
            # ì§€í‘œ ê³„ì‚°
            metrics = {
                'scenario_id': scenario['id'],
                'dipperp_success': self._check_path_validity(scenario, dipperp_path),
                'astar_success': self._check_path_validity(scenario, astar_path),
                'dipperp_cost': self._calculate_path_cost(scenario, dipperp_path),
                'astar_cost': self._calculate_path_cost(scenario, astar_path),
                'dipperp_length': self._calculate_path_length(dipperp_path),
                'astar_length': self._calculate_path_length(astar_path),
                'dipperp_smoothness': self._calculate_smoothness(dipperp_path),
                'astar_smoothness': self._calculate_smoothness(astar_path),
                'dipperp_time': dipperp_time,
                'astar_time': astar_time,
                'speedup': astar_time / dipperp_time if dipperp_time > 0 else float('inf')
            }
            
            quantitative_results.append(metrics)
        
        self.results['quantitative'] = quantitative_results
        print("âœ… ì •ëŸ‰ì  í‰ê°€ ì™„ë£Œ")
        
        return quantitative_results
    
    def _check_path_validity(self, scenario, path):
        """ê²½ë¡œ ìœ íš¨ì„± ê²€ì‚¬"""
        if not path or len(path) < 2:
            return False
        
        # ì‹œì‘/ëª©í‘œì  ë„ë‹¬ í™•ì¸
        start_dist = np.linalg.norm(np.array(path[0]) - np.array(scenario['start_pos']))
        goal_dist = np.linalg.norm(np.array(path[-1]) - np.array(scenario['goal_pos']))
        
        if start_dist > 1.0 or goal_dist > 1.0:
            return False
        
        # ì¥ì• ë¬¼ ê´€í†µ í™•ì¸
        for point in path:
            if not self.simulator.is_position_safe(point):
                return False
        
        return True
    
    def _calculate_path_cost(self, scenario, path):
        """ê²½ë¡œ ë¹„ìš© ê³„ì‚°"""
        if not path:
            return float('inf')
        
        total_cost = 0
        for point in path:
            x_idx = int((point[0] + 6) / 0.2)
            y_idx = int((point[1] + 6) / 0.2)
            if 0 <= x_idx < 60 and 0 <= y_idx < 60:
                total_cost += scenario['fused_cost_map'][y_idx, x_idx]
        
        return total_cost / len(path)  # í‰ê·  ë¹„ìš©
    
    def _calculate_path_length(self, path):
        """ê²½ë¡œ ê¸¸ì´ ê³„ì‚°"""
        if not path or len(path) < 2:
            return 0
        
        total_length = 0
        for i in range(len(path) - 1):
            dist = np.linalg.norm(np.array(path[i+1]) - np.array(path[i]))
            total_length += dist
        
        return total_length
    
    def _calculate_smoothness(self, path):
        """ê²½ë¡œ ë¶€ë“œëŸ¬ì›€ ê³„ì‚° (ê°ë„ ë³€í™”ì˜ í‘œì¤€í¸ì°¨)"""
        if not path or len(path) < 3:
            return 0
        
        angles = []
        for i in range(1, len(path) - 1):
            v1 = np.array(path[i]) - np.array(path[i-1])
            v2 = np.array(path[i+1]) - np.array(path[i])
            
            if np.linalg.norm(v1) > 0 and np.linalg.norm(v2) > 0:
                cos_angle = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))
                angle = np.arccos(np.clip(cos_angle, -1, 1))
                angles.append(angle)
        
        return np.std(angles) if angles else 0
    
    def _calculate_path_quality(self, scenario, dipperp_path, astar_path):
        """ê²½ë¡œ í’ˆì§ˆ ì¢…í•© í‰ê°€"""
        return {
            'scenario_id': scenario['id'],
            'dipperp_valid': self._check_path_validity(scenario, dipperp_path),
            'astar_valid': self._check_path_validity(scenario, astar_path),
            'cost_ratio': (self._calculate_path_cost(scenario, dipperp_path) / 
                          max(self._calculate_path_cost(scenario, astar_path), 1e-6)),
            'length_ratio': (self._calculate_path_length(dipperp_path) / 
                           max(self._calculate_path_length(astar_path), 1e-6)),
            'smoothness_ratio': (self._calculate_smoothness(dipperp_path) / 
                               max(self._calculate_smoothness(astar_path), 1e-6))
        }
    
    def generate_report(self, save_path="evaluation_report.json"):
        """í‰ê°€ ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±"""
        print("ğŸ“‹ í‰ê°€ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
        
        # ì •ëŸ‰ì  ê²°ê³¼ í†µê³„
        df = pd.DataFrame(self.results['quantitative'])
        
        summary = {
            'overview': {
                'total_scenarios': len(df),
                'dipperp_success_rate': df['dipperp_success'].mean(),
                'astar_success_rate': df['astar_success'].mean(),
                'average_speedup': df['speedup'].mean(),
                'median_speedup': df['speedup'].median()
            },
            'performance_comparison': {
                'cost_improvement': 1 - (df['dipperp_cost'] / df['astar_cost']).mean(),
                'length_efficiency': 1 - (df['dipperp_length'] / df['astar_length']).mean(),
                'smoothness_improvement': 1 - (df['dipperp_smoothness'] / df['astar_smoothness']).mean(),
                'time_improvement': 1 - (df['dipperp_time'] / df['astar_time']).mean()
            },
            'detailed_results': self.results
        }
        
        # JSON ì €ì¥
        with open(save_path, 'w') as f:
            json.dump(summary, f, indent=2, default=str)
        
        # ì½˜ì†” ì¶œë ¥
        print("\n" + "="*60)
        print("ğŸ“Š DiPPeR í‰ê°€ ê²°ê³¼ ìš”ì•½")
        print("="*60)
        print(f"ì´ ì‹œë‚˜ë¦¬ì˜¤: {summary['overview']['total_scenarios']}")
        print(f"DiPPeR ì„±ê³µë¥ : {summary['overview']['dipperp_success_rate']:.2%}")
        print(f"A* ì„±ê³µë¥ : {summary['overview']['astar_success_rate']:.2%}")
        print(f"í‰ê·  ì†ë„ í–¥ìƒ: {summary['overview']['average_speedup']:.2f}x")
        print(f"ë¹„ìš© ê°œì„ : {summary['performance_comparison']['cost_improvement']:.2%}")
        print(f"ê¸¸ì´ íš¨ìœ¨ì„±: {summary['performance_comparison']['length_efficiency']:.2%}")
        print(f"ë¶€ë“œëŸ¬ì›€ ê°œì„ : {summary['performance_comparison']['smoothness_improvement']:.2%}")
        print(f"ì‹œê°„ ê°œì„ : {summary['performance_comparison']['time_improvement']:.2%}")
        print("="*60)
        
        print(f"âœ… ìƒì„¸ ë¦¬í¬íŠ¸ ì €ì¥: {save_path}")
        return summary

def main():
    parser = argparse.ArgumentParser(description='DiPPeR ëª¨ë¸ ê²€ì¦')
    parser.add_argument('--model_path', required=True, help='í•™ìŠµëœ DiPPeR ëª¨ë¸ ê²½ë¡œ')
    parser.add_argument('--xml_file', default='scenarios/Circulation1.xml', help='ì‹œë®¬ë ˆì´ì…˜ XML íŒŒì¼')
    parser.add_argument('--num_scenarios', type=int, default=100, help='í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ìˆ˜')
    parser.add_argument('--save_dir', default='evaluation_results', help='ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬')
    
    args = parser.parse_args()
    
    # ê²€ì¦ ì‹¤í–‰
    validator = DiPPeRValidator(args.model_path, args.xml_file)
    
    # 1. í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ìˆ˜ì§‘
    scenarios = validator.collect_test_scenarios(args.num_scenarios)
    
    # 2. ì •ì„±ì  í‰ê°€
    validator.qualitative_evaluation(scenarios, args.save_dir)
    
    # 3. ì •ëŸ‰ì  í‰ê°€
    validator.quantitative_evaluation(scenarios)
    
    # 4. ë¦¬í¬íŠ¸ ìƒì„±
    validator.generate_report(f"{args.save_dir}/evaluation_report.json")

if __name__ == "__main__":
    main() 