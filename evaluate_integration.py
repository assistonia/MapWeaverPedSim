#!/usr/bin/env python3
"""
DiPPeR í†µí•© ì‹œìŠ¤í…œ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
End-to-End ì‹œë®¬ë ˆì´ì…˜ ì„±ëŠ¥ í‰ê°€
"""

import torch
import numpy as np
import matplotlib.pyplot as plt
import json
import time
from pathlib import Path
import argparse
from tqdm import tqdm
import pandas as pd

from robot_simuator_dippeR import RobotSimulatorDiPPeR

class IntegrationValidator:
    """DiPPeR í†µí•© ì‹œìŠ¤í…œ ê²€ì¦ í´ë˜ìŠ¤"""
    
    def __init__(self, model_path, xml_file):
        self.model_path = model_path
        self.xml_file = xml_file
        
        # ê²°ê³¼ ì €ì¥ìš©
        self.results = {
            'dipperp_system': [],
            'astar_system': []
        }
    
    def run_comparative_evaluation(self, num_episodes=50, max_steps=500):
        """DiPPeR vs A* ì‹œìŠ¤í…œ ë¹„êµ í‰ê°€"""
        print(f"ğŸš€ í†µí•© ì‹œìŠ¤í…œ ë¹„êµ í‰ê°€ ì‹œì‘ ({num_episodes}ê°œ ì—í”¼ì†Œë“œ)")
        
        # í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„±
        scenarios = self._generate_test_scenarios(num_episodes)
        
        # DiPPeR ì‹œìŠ¤í…œ í‰ê°€
        print("\nğŸ”® DiPPeR ê¸°ë°˜ ì‹œìŠ¤í…œ í‰ê°€...")
        dipperp_results = self._evaluate_system(scenarios, use_dipperp=True, max_steps=max_steps)
        
        # A* ì‹œìŠ¤í…œ í‰ê°€
        print("\nâ­ A* ê¸°ë°˜ ì‹œìŠ¤í…œ í‰ê°€...")
        astar_results = self._evaluate_system(scenarios, use_dipperp=False, max_steps=max_steps)
        
        # ê²°ê³¼ ì €ì¥
        self.results['dipperp_system'] = dipperp_results
        self.results['astar_system'] = astar_results
        
        return dipperp_results, astar_results
    
    def _generate_test_scenarios(self, num_scenarios):
        """ë‹¤ì–‘í•œ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„±"""
        scenarios = []
        
        # ë‚œì´ë„ë³„ ì‹œë‚˜ë¦¬ì˜¤
        difficulty_configs = [
            {'name': 'easy', 'num_agents': 5, 'agent_speed': 0.5, 'count': num_scenarios//3},
            {'name': 'medium', 'num_agents': 10, 'agent_speed': 0.8, 'count': num_scenarios//3},
            {'name': 'hard', 'num_agents': 15, 'agent_speed': 1.0, 'count': num_scenarios - 2*(num_scenarios//3)}
        ]
        
        scenario_id = 0
        for config in difficulty_configs:
            for _ in range(config['count']):
                start_pos = self._generate_safe_position()
                goal_pos = self._generate_safe_position()
                
                # ìµœì†Œ ê±°ë¦¬ ë³´ì¥
                while np.linalg.norm(np.array(start_pos) - np.array(goal_pos)) < 3.0:
                    goal_pos = self._generate_safe_position()
                
                scenarios.append({
                    'id': scenario_id,
                    'difficulty': config['name'],
                    'start_pos': start_pos,
                    'goal_pos': goal_pos,
                    'num_agents': config['num_agents'],
                    'agent_speed': config['agent_speed']
                })
                scenario_id += 1
        
        return scenarios
    
    def _generate_safe_position(self):
        """ì•ˆì „í•œ ìœ„ì¹˜ ìƒì„±"""
        safe_zones = [
            (-4.5, -0.5, -4.5, 1.5),   # ì™¼ìª½ ìœ„
            (-4.5, -0.5, -2.0, -1.5),  # ì™¼ìª½ ì•„ë˜
            (2.5, 3.5, -4.5, -0.5),    # ì˜¤ë¥¸ìª½ ì•„ë˜
            (2.5, 3.5, 1.0, 2.0),      # ì˜¤ë¥¸ìª½ ìœ„
            (-0.5, 1.5, 3.0, 4.5)      # ìœ„ìª½ ì¤‘ì•™
        ]
        
        for _ in range(50):
            zone = safe_zones[np.random.randint(len(safe_zones))]
            pos = [np.random.uniform(zone[0], zone[1]), 
                   np.random.uniform(zone[2], zone[3])]
            # ê°„ë‹¨í•œ ì•ˆì „ì„± ì²´í¬ (ì‹¤ì œ ì‹œë®¬ë ˆì´í„° ì—†ì´)
            if not self._is_in_obstacle(pos):
                return pos
        
        return [0.0, 0.0]  # í´ë°±
    
    def _is_in_obstacle(self, pos):
        """ê°„ë‹¨í•œ ì¥ì• ë¬¼ ì²´í¬"""
        # Circulation1.xmlì˜ ì¥ì• ë¬¼ ì˜ì—­ (ëŒ€ëµì )
        obstacles = [
            (1.5, 2.5, 0.0, 1.0),     # ì¥ì• ë¬¼ 1
            (-3.0, -1.5, -3.0, -2.0)  # ì¥ì• ë¬¼ 2
        ]
        
        for obs in obstacles:
            if obs[0] <= pos[0] <= obs[1] and obs[2] <= pos[1] <= obs[3]:
                return True
        return False
    
    def _evaluate_system(self, scenarios, use_dipperp, max_steps):
        """ì‹œìŠ¤í…œ ì„±ëŠ¥ í‰ê°€"""
        results = []
        
        system_name = "DiPPeR" if use_dipperp else "A*"
        
        for scenario in tqdm(scenarios, desc=f"{system_name} í‰ê°€"):
            # ì‹œë®¬ë ˆì´í„° ì´ˆê¸°í™”
            if use_dipperp and Path(self.model_path).exists():
                simulator = RobotSimulatorDiPPeR(self.xml_file, model_path=self.model_path)
                simulator.use_dipperp = True
            else:
                simulator = RobotSimulatorDiPPeR(self.xml_file, model_path=None)
                simulator.use_dipperp = False
            
            # ì‹œë‚˜ë¦¬ì˜¤ ì„¤ì •
            simulator.robot_pos = scenario['start_pos'].copy()
            simulator.target_pos = scenario['goal_pos'].copy()
            
            # í‰ê°€ ì‹¤í–‰
            episode_result = self._run_single_episode(
                simulator, scenario, max_steps, use_dipperp
            )
            
            results.append(episode_result)
        
        return results
    
    def _run_single_episode(self, simulator, scenario, max_steps, use_dipperp):
        """ë‹¨ì¼ ì—í”¼ì†Œë“œ ì‹¤í–‰ ë° í‰ê°€"""
        start_time = time.time()
        
        # ì„±ëŠ¥ ì§€í‘œ ì´ˆê¸°í™”
        metrics = {
            'scenario_id': scenario['id'],
            'difficulty': scenario['difficulty'],
            'system_type': 'DiPPeR' if use_dipperp else 'A*',
            'success': False,
            'collision_count': 0,
            'total_steps': 0,
            'total_time': 0,
            'total_distance': 0,
            'average_speed': 0,
            'path_efficiency': 0,
            'planning_time_total': 0,
            'planning_calls': 0,
            'stuck_episodes': 0
        }
        
        # ì´ˆê¸° ìœ„ì¹˜ ê¸°ë¡
        prev_pos = simulator.robot_pos.copy()
        path_points = [prev_pos.copy()]
        planning_times = []
        
        # ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰
        for step in range(max_steps):
            step_start = time.time()
            
            # í•œ ìŠ¤í… ì‹¤í–‰
            simulator.update()
            
            # ìœ„ì¹˜ ê¸°ë¡
            current_pos = simulator.robot_pos.copy()
            path_points.append(current_pos)
            
            # ê±°ë¦¬ ê³„ì‚°
            step_distance = np.linalg.norm(np.array(current_pos) - np.array(prev_pos))
            metrics['total_distance'] += step_distance
            prev_pos = current_pos
            
            # ëª©í‘œ ë„ë‹¬ ì²´í¬
            goal_distance = np.linalg.norm(np.array(current_pos) - np.array(scenario['goal_pos']))
            if goal_distance < 0.5:  # ëª©í‘œ ë„ë‹¬
                metrics['success'] = True
                break
            
            # ì •ì²´ ê°ì§€ (ìµœê·¼ 10ìŠ¤í… ë™ì•ˆ 0.1m ë¯¸ë§Œ ì´ë™)
            if step >= 10:
                recent_movement = np.linalg.norm(
                    np.array(path_points[-1]) - np.array(path_points[-10])
                )
                if recent_movement < 0.1:
                    metrics['stuck_episodes'] += 1
                    if metrics['stuck_episodes'] > 5:  # ì—°ì† ì •ì²´
                        break
            
            metrics['total_steps'] = step + 1
        
        # ìµœì¢… ì§€í‘œ ê³„ì‚°
        metrics['total_time'] = time.time() - start_time
        metrics['average_speed'] = metrics['total_distance'] / max(metrics['total_time'], 1e-6)
        
        # ê²½ë¡œ íš¨ìœ¨ì„± (ì§ì„  ê±°ë¦¬ ëŒ€ë¹„ ì‹¤ì œ ì´ë™ ê±°ë¦¬)
        straight_distance = np.linalg.norm(
            np.array(scenario['goal_pos']) - np.array(scenario['start_pos'])
        )
        metrics['path_efficiency'] = straight_distance / max(metrics['total_distance'], 1e-6)
        
        return metrics
    
    def generate_comparison_report(self, save_path="integration_report.json"):
        """ë¹„êµ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""
        print("ğŸ“Š í†µí•© ì‹œìŠ¤í…œ ë¹„êµ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
        
        dipperp_df = pd.DataFrame(self.results['dipperp_system'])
        astar_df = pd.DataFrame(self.results['astar_system'])
        
        # ì „ì²´ ì„±ëŠ¥ ë¹„êµ
        comparison = {
            'overall_performance': {
                'dipperp_success_rate': dipperp_df['success'].mean(),
                'astar_success_rate': astar_df['success'].mean(),
                'dipperp_avg_collision': dipperp_df['collision_count'].mean(),
                'astar_avg_collision': astar_df['collision_count'].mean(),
                'dipperp_avg_time': dipperp_df['total_time'].mean(),
                'astar_avg_time': astar_df['total_time'].mean(),
                'dipperp_avg_speed': dipperp_df['average_speed'].mean(),
                'astar_avg_speed': astar_df['average_speed'].mean(),
                'dipperp_path_efficiency': dipperp_df['path_efficiency'].mean(),
                'astar_path_efficiency': astar_df['path_efficiency'].mean()
            }
        }
        
        # ë‚œì´ë„ë³„ ë¹„êµ
        comparison['difficulty_analysis'] = {}
        for difficulty in ['easy', 'medium', 'hard']:
            dipperp_subset = dipperp_df[dipperp_df['difficulty'] == difficulty]
            astar_subset = astar_df[astar_df['difficulty'] == difficulty]
            
            if len(dipperp_subset) > 0 and len(astar_subset) > 0:
                comparison['difficulty_analysis'][difficulty] = {
                    'dipperp_success_rate': dipperp_subset['success'].mean(),
                    'astar_success_rate': astar_subset['success'].mean(),
                    'dipperp_avg_collision': dipperp_subset['collision_count'].mean(),
                    'astar_avg_collision': astar_subset['collision_count'].mean(),
                    'dipperp_avg_time': dipperp_subset['total_time'].mean(),
                    'astar_avg_time': astar_subset['total_time'].mean()
                }
        
        # ìƒì„¸ ê²°ê³¼ í¬í•¨
        comparison['detailed_results'] = {
            'dipperp_system': self.results['dipperp_system'],
            'astar_system': self.results['astar_system']
        }
        
        # JSON ì €ì¥
        with open(save_path, 'w') as f:
            json.dump(comparison, f, indent=2, default=str)
        
        # ì½˜ì†” ì¶œë ¥
        self._print_comparison_summary(comparison)
        
        print(f"âœ… ìƒì„¸ ë¦¬í¬íŠ¸ ì €ì¥: {save_path}")
        return comparison
    
    def _print_comparison_summary(self, comparison):
        """ë¹„êµ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        overall = comparison['overall_performance']
        
        print("\n" + "="*80)
        print("ğŸ† DiPPeR vs A* í†µí•© ì‹œìŠ¤í…œ ì„±ëŠ¥ ë¹„êµ")
        print("="*80)
        
        print(f"ğŸ“ˆ ì „ì²´ ì„±ëŠ¥ ë¹„êµ:")
        print(f"  ì„±ê³µë¥ :      DiPPeR {overall['dipperp_success_rate']:.2%} vs A* {overall['astar_success_rate']:.2%}")
        print(f"  í‰ê·  ì¶©ëŒ:   DiPPeR {overall['dipperp_avg_collision']:.2f} vs A* {overall['astar_avg_collision']:.2f}")
        print(f"  í‰ê·  ì‹œê°„:   DiPPeR {overall['dipperp_avg_time']:.2f}s vs A* {overall['astar_avg_time']:.2f}s")
        print(f"  í‰ê·  ì†ë„:   DiPPeR {overall['dipperp_avg_speed']:.2f} vs A* {overall['astar_avg_speed']:.2f}")
        print(f"  ê²½ë¡œ íš¨ìœ¨ì„±: DiPPeR {overall['dipperp_path_efficiency']:.2f} vs A* {overall['astar_path_efficiency']:.2f}")
        
        # ê°œì„  ì§€í‘œ
        success_improvement = (overall['dipperp_success_rate'] - overall['astar_success_rate']) * 100
        collision_reduction = (overall['astar_avg_collision'] - overall['dipperp_avg_collision']) / max(overall['astar_avg_collision'], 1e-6) * 100
        
        print(f"\nğŸ¯ í•µì‹¬ ê°œì„  ì§€í‘œ:")
        print(f"  ì„±ê³µë¥  ê°œì„ :   {success_improvement:+.1f}%")
        print(f"  ì¶©ëŒ ê°ì†Œ:     {collision_reduction:+.1f}%")
        
        print("="*80)

def main():
    parser = argparse.ArgumentParser(description='DiPPeR í†µí•© ì‹œìŠ¤í…œ ê²€ì¦')
    parser.add_argument('--model_path', required=True, help='í•™ìŠµëœ DiPPeR ëª¨ë¸ ê²½ë¡œ')
    parser.add_argument('--xml_file', default='Circulation1.xml', help='ì‹œë®¬ë ˆì´ì…˜ XML íŒŒì¼')
    parser.add_argument('--num_episodes', type=int, default=30, help='í…ŒìŠ¤íŠ¸ ì—í”¼ì†Œë“œ ìˆ˜')
    parser.add_argument('--max_steps', type=int, default=500, help='ì—í”¼ì†Œë“œë‹¹ ìµœëŒ€ ìŠ¤í…')
    parser.add_argument('--save_dir', default='integration_results', help='ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬')
    
    args = parser.parse_args()
    
    # ê²€ì¦ ì‹¤í–‰
    validator = IntegrationValidator(args.model_path, args.xml_file)
    
    # ë¹„êµ í‰ê°€
    dipperp_results, astar_results = validator.run_comparative_evaluation(
        args.num_episodes, args.max_steps
    )
    
    # ë¦¬í¬íŠ¸ ìƒì„±
    Path(args.save_dir).mkdir(exist_ok=True)
    validator.generate_comparison_report(f"{args.save_dir}/integration_report.json")

if __name__ == "__main__":
    main() 